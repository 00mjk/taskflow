namespace tf {

/** @page chapter7 C7: GPU Tasking (%cudaFlowCapturer)

You can create a %cudaFlow through <i>stream capture</i>, which allows you
to capture information on GPU activities that are submitted to the stream 
managed by a @em %cudaFlowCapturer.

@section C7_Capture_a_cudaFlow Capture a cudaFlow

When your program has no access to direct kernel calls but invoke
it through a stream-based interface (e.g., @cuBLAS library functions),
you can use tf::cudaFlowCapturer to capture the GPU activities into a %cudaFlow.
A %cudaFlowCapturer is similar to a %cudaFlow except it froms a GPU task graph
through stream capture.
You use the method tf::cudaFlowCapturer::on
to capture a sequence of @em asynchronous CUDA operations through the given stream.
The following example creates a CUDA graph that captures two kernel tasks, 
@c task_1 and @c task_2, where @c task_1 (i.e., @c my_kernel_1) 
runs before @c task_2 (i.e., @c my_kernel_2).

@code{.cpp}
taskflow.emplace([](tf::cudaFlowCapturer& capturer){
  // capture my_kernel_1
  auto task_1 = capturer.on([&](cudaStream_t stream){  // stream is managed by the capturer
    my_kernel_1<<<grid_1, block_1, shm_size_1, stream>>>(my_parameters_1);
  });
  // capture my_kernel_2
  auto task_2 = capturer.on([&](cudaStream_t stream){  // stream is managed by the capturer
    my_kernel_2<<<grid_2, block_2, shm_size_2, stream>>>(my_parameters_2);
  });
  // my_kernel_1 runs before my_kernel_2
  task_1.precede(task_2);
});
@endcode

Inside tf::cudaFlowCapturer::on, you should @em NOT modify the properties of 
the stream argument but use it to capture @em asynchronous GPU operations
(e.g., @c kernel, @c cudaMemcpyAsync).
The stream object passed to each tf::cudaFlowCapturer::on call may differ,
and it depends on how the internal optimization algorithm maximizes the 
GPU parallelism.

A %cudaFlowCapturer inherits tf::cudaFlowCapturerBase that defines a set of 
methods for capturing common GPU operations.


*/

}


