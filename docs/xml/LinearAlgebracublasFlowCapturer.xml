<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.14">
  <compounddef id="LinearAlgebracublasFlowCapturer" kind="page">
    <compoundname>LinearAlgebracublasFlowCapturer</compoundname>
    <title>Linear Algebra (cublasFlowCapturer)</title>
    <tableofcontents/>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para>Taskflow provides a library <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> to program and accelerate <emphasis>basic linear algebra subprograms</emphasis> (BLAS) on top of <ulink url="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</ulink>.</para><para><image type="html" name="LinearAlgebra.png" width="50%"></image>
</para><sect1 id="LinearAlgebracublasFlowCapturer_1WhatIsBLAS">
<title>What is BLAS?</title>
<para>The BLAS (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations. There are three levels:</para><para><orderedlist>
<listitem><para>Level 1: performs scalar, vector, and vector-vector operations</para></listitem><listitem><para>Level 2: performs matrix-vector operations</para></listitem><listitem><para>Level 3: performs matrix-matrix operations</para></listitem></orderedlist>
</para><para>BLAS is commonly used by linear algebra software. The <ulink url="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</ulink> library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the Nvidia CUDA runtime and it allows users to access the computational resources of Nvidia GPUs.</para></sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1HowToUsecublasFlowCapturer">
<title>What is a cublasFlow Capturer? Why?</title>
<para><ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> provides an interface over native cuBLAS functions and allows users to express linear algebra algorithms using a <emphasis>task graph model</emphasis>. We transform the task graph into a CUDA graph using a stream capture algorithm optimized for maximum concurrency. When a cuBLAS program is transformed into a CUDA graph, we can launch the entire graph using a single kernel call to largely reduce the kernel call overheads and efficiently overlap concurrent kernels. This organization is particularly suitable for large linear algebra programs that contain hundreds of cuBLAS operations.</para><para>The following example use <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> to perform a 2-norm operation on a vector.</para><para><programlisting filename=".cpp"><codeline><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>N<sp/>=<sp/>1024;</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Executor" kindref="compound">tf::Executor</ref><sp/>executor;</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref><sp/>taskflow(</highlight><highlight class="stringliteral">&quot;cublas<sp/>2-norm&quot;</highlight><highlight class="normal">);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>initialize<sp/>an<sp/>unit<sp/>vector</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="cpp/container/vector" kindref="compound" external="/Users/twhuang/PhD/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::vector&lt;float&gt;</ref><sp/>hvec(N,<sp/>1);<sp/></highlight></codeline>
<codeline><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><sp/>hres;<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>cpu<sp/>vector</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>gvec<sp/>=<sp/>tf::cuda_malloc_device&lt;float&gt;(N);<sp/><sp/></highlight><highlight class="comment">//<sp/>gpu<sp/>vector</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>gres<sp/>=<sp/>tf::cuda_malloc_device&lt;float&gt;(1);<sp/><sp/></highlight><highlight class="comment">//<sp/>gpu<sp/>result</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlowCapturer" kindref="compound">tf::cudaFlowCapturer</ref>&amp;<sp/>capturer){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>a<sp/>cuBLAS<sp/>flow<sp/>capturer</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>blas<sp/>=<sp/>capturer.<ref refid="classtf_1_1cudaFlowCapturer_1a49dd9727aeb5bccd7d826c6b11a6882d" kindref="member">make_capturer</ref>&lt;<ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref>&gt;();</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d<sp/>=<sp/>capturer.<ref refid="classtf_1_1cudaFlowCapturerBase_1a9fd8983c782f841bba6b10de39becdf6" kindref="member">copy</ref>(gvec,<sp/>hvec.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>nrm<sp/>=<sp/>blas-&gt;nrm2(N,<sp/>gvec,<sp/>1,<sp/>gres).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;2-norm&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h<sp/>=<sp/>capturer.<ref refid="classtf_1_1cudaFlowCapturerBase_1a9fd8983c782f841bba6b10de39becdf6" kindref="member">copy</ref>(&amp;hres,<sp/>gres,<sp/>1).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>nrm.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;capturer&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">executor.<ref refid="classtf_1_1Executor_1a81f35d5b0a20ac0646447eb80d97c0aa" kindref="member">run</ref>(taskflow).wait();</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1Taskflow_1ac433018262e44b12c4cc9f0c4748d758" kindref="member">dump</ref>(<ref refid="cpp/io/basic_ostream" kindref="compound" external="/Users/twhuang/PhD/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::cout</ref>);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">assert(hres<sp/>==<sp/>32);</highlight></codeline>
</programlisting></para><para><dotfile name="/Users/twhuang/PhD/Code/taskflow/doxygen/images/cublas_flow_capturer_norm2.dot"></dotfile>
</para></sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1DataModelOscublasFlowCapturer">
<title>Understand the Data Model</title>
<para>The data pointers used within <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> must sit in GPU memory space, including scalar pointers (<computeroutput>alpha</computeroutput> and <computeroutput>beta</computeroutput>), input pointers (e.g., vectors, matrices), and output pointers (e.g., result). By default, we set the pointer mode to <computeroutput>CUBLAS_POINTER_MODE_DEVICE</computeroutput>. You must allocate required matrices and vectors in the GPU memory space, fill them with data, call the methods defined in <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref>, and then upload the results from GPU memory space back to the host.</para><para><simplesect kind="note"><para><ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> currently supports only <computeroutput>float</computeroutput> and <computeroutput>double</computeroutput> data types.</para></simplesect>
The cuBLAS library uses <emphasis>column-major storage</emphasis> and 1-based indexing. Since C/C++ adopts row-major storage, we cannot use the native array semantics when matrix-matrix or matrix-vector operations are involved. We often need extra transposition on input matrices before these operations can take place correctly. In terms of storage, a row-major matrix is equivalent to a transposed column-major matrix, as shown below:</para><para><formula id="0">\[ A_{RowMajor} \iff A^T_{ColumnMajor} \]</formula></para><sect2 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerDataModelExample">
<title>Example</title>
<para>Suppose we have a method <computeroutput>matmul(A, B, C)</computeroutput> that multiplies two matrices <computeroutput>A</computeroutput> and <computeroutput>B</computeroutput> and stores the result in <computeroutput>C</computeroutput>, using column-major storage. In C/C++, data layout is mostly row-major. Since we know a row-major matrix is equivalent in storage to a transposed column-major matrix, we can take a transposed view of this multiplication:</para><para><formula id="1">\[ C^T = B^T \times A^T \]</formula></para><para>If the given matrices <computeroutput>A</computeroutput>, <computeroutput>B</computeroutput>, and <computeroutput>C</computeroutput> are in row-major storage, calling <computeroutput>matmul(A, B, C)</computeroutput> is equivalent to the above transposed version. The function stores the result of transposed <computeroutput>C</computeroutput> in column-major storage which in turns translates to row-major layout of <computeroutput>C</computeroutput> <ndash/> <emphasis>our desired solution</emphasis>.</para></sect2>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerLevel-1">
<title>Use Level-1 Methods</title>
<para>We currently support the following level-1 methods:</para><para><itemizedlist>
<listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1ab1357bb1728f5fe526acef8afee7111e" kindref="member">tf::cublasFlowCapturer::amax</ref> finds the smallest element index of the maximum absolute magnitude over a vector</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a7a6485c37d50b9c79205f728ab380929" kindref="member">tf::cublasFlowCapturer::amin</ref> finds the smallest element index of the minimum absolute magnitude over a vector</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1ab7672cee3d219ccc75c48b62cf1d1bad" kindref="member">tf::cublasFlowCapturer::asum</ref> computes the sum of absolute values of elements over a vector</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a56f8649d43652597da1c9b0a5f88b0ee" kindref="member">tf::cublasFlowCapturer::axpy</ref> multiplies a vector by a scalar and adds it to another vector</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlowCapturerBase_1a9fd8983c782f841bba6b10de39becdf6" kindref="member">tf::cublasFlowCapturer::copy</ref> copies a vector into another vector</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1afdfa01d9f277051e44d7ed9663555b52" kindref="member">tf::cublasFlowCapturer::dot</ref> computes the dot product of two vectors</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a8000fc6dbbb6f6f5a033f1b365e80d38" kindref="member">tf::cublasFlowCapturer::nrm2</ref> computes the Euclidean norm of a vector</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1adb8f5d3137f5ccb3469a5bdde454a8bf" kindref="member">tf::cublasFlowCapturer::scal</ref> multiples a vector by a scalar</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a32451b05fd7eb937ce8e807b5d5abe1f" kindref="member">tf::cublasFlowCapturer::swap</ref> interchanges the elements of two vectors</para></listitem></itemizedlist>
</para><para>Our level-1 methods capture the native <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-1-function-reference">cublas level-1 calls</ulink> with internal stream(s) optimized for maximum concurrency.</para></sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerLeve2-1">
<title>Use Level-2 Methods</title>
<para>We currently support the following level-2 methods:</para><para><itemizedlist>
<listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a72185bf94321948b5b3657cc9c52ad0a" kindref="member">tf::cublasFlowCapturer::gemv</ref> performs general matrix-vector multiplication</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a3a492f3f22949e0e6b1058113eb475d0" kindref="member">tf::cublasFlowCapturer::c_gemv</ref> performs general matrix-vector multiplication on C-styled row-major layout</para></listitem></itemizedlist>
</para><para>Our level-2 methods capture the native <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">cublas level-2 calls</ulink> with internal stream(s) optimized for maximum concurrency.</para></sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerLevel-3">
<title>Use Level-3 Methods</title>
<para>We currently support the following level-3 methods:</para><para><itemizedlist>
<listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a30b437e511b5719f6253d3a9cf0a992c" kindref="member">tf::cublasFlowCapturer::geam</ref> performs matrix-matrix addition/transposition</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a756dc6637521ef4f2249711effd1d0f5" kindref="member">tf::cublasFlowCapturer::c_geam</ref> performs matrix-matrix addition/transposition on C-styled row-major storage</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a8adbe06476f146b27bb00ba6054e5879" kindref="member">tf::cublasFlowCapturer::gemm</ref> performs general matrix-matrix multiplication</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1aecfd3b623b457d277dca40c2e1b3c1c0" kindref="member">tf::cublasFlowCapturer::c_gemm</ref> performs general matrix-matrix multiplication on C-styled row-major storage</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a56af0e8ed80e5626fe2f594608afa405" kindref="member">tf::cublasFlowCapturer::gemm_batched</ref> performs batched general matrix-matrix multiplication</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1aa9415957e3e48df65dc3baad86d05b38" kindref="member">tf::cublasFlowCapturer::c_gemm_batched</ref> performs batched general matrix-matrix multiplication on C-styled row-major storage</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a36ecdcea0f24575187e44374e583df2e" kindref="member">tf::cublasFlowCapturer::gemm_sbatched</ref> performs batched general matrix-matrix multiplication with strided memory access</para></listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1ae57c53a1a07c0b4f73d90bf21fee4e1c" kindref="member">tf::cublasFlowCapturer::c_gemm_sbatched</ref> performs batched general matrix-matrix multiplication with strided memory access on C-styled row-major storage</para></listitem></itemizedlist>
</para><para>Our level-3 methods capture the native <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">cublas level-3 calls</ulink> and <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#blas-like-extension">cublas-extension calls</ulink> with internal stream(s) optimized for maximum concurrency.</para></sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerExtension">
<title>Extend to Other cuBLAS Methods</title>
<para><ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> is derived from <ref refid="classtf_1_1cudaFlowCapturerBase" kindref="compound">tf::cudaFlowCapturerBase</ref> and is created from a factory interface <ref refid="classtf_1_1cudaFlowCapturer_1a49dd9727aeb5bccd7d826c6b11a6882d" kindref="member">tf::cudaFlowCapturer::make_capturer</ref>. You can use all the base methods <ref refid="classtf_1_1cudaFlowCapturerBase_1adf651356def71f613c589c29588398c2" kindref="member">tf::cudaFlowCapturerBase::on</ref> to capture other cuBLAS methods that are not defined in <ref refid="classtf_1_1cudaFlowCapturer" kindref="compound">tf::cudaFlowCapturer</ref>. The following example captures the Hermitian rank-k update, <computeroutput>cublasCherkx</computeroutput>.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlowCapturer" kindref="compound">tf::cudaFlowCapturer</ref>&amp;<sp/>capturer){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>a<sp/>cublasFlow<sp/>capturer</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>blas<sp/>=<sp/>capturer.<ref refid="classtf_1_1cudaFlowCapturer_1a49dd9727aeb5bccd7d826c6b11a6882d" kindref="member">make_capturer</ref>&lt;<ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref>&gt;();</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>use<sp/>the<sp/>base<sp/>method<sp/>tf::cudaFlowCapturer::on<sp/>to<sp/>capture<sp/>other<sp/>functions</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>blas-&gt;<ref refid="classtf_1_1cudaFlowCapturerBase_1adf651356def71f613c589c29588398c2" kindref="member">on</ref>([&amp;](cudaStream_t<sp/>stream){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>cublasSetStream(blas-&gt;native_handle(),<sp/>stream);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>cublasCherkx(blas-&gt;native_handle(),<sp/>your_args...);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>}).name(</highlight><highlight class="stringliteral">&quot;Hermitian<sp/>rank-k<sp/>update&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;capturer&quot;</highlight><highlight class="normal">);</highlight></codeline>
</programlisting></para></sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerKnowMore">
<title>Know More About cublasFlow Capturer</title>
<para>We summarize below resources for you to know more about <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref>:<itemizedlist>
<listitem><para>Study the reference of <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> and <ref refid="classtf_1_1cudaFlowCapturer" kindref="compound">tf::cudaFlowCapturer</ref></para></listitem><listitem><para>Contribute to <ref refid="cublas__flow_8hpp" kindref="compound">cublas_flow.hpp</ref> by adding more BLAS methods</para></listitem><listitem><para>See the complete list of BLAS functions offered by <ulink url="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</ulink> </para></listitem></itemizedlist>
</para></sect1>
    </detaileddescription>
  </compounddef>
</doxygen>
