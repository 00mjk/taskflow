<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.20" xml:lang="en-US">
  <compounddef id="LinearAlgebracublasFlowCapturer" kind="page">
    <compoundname>LinearAlgebracublasFlowCapturer</compoundname>
    <title>Linear Algebra (cublasFlowCapturer)</title>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para>Taskflow provides a library <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> to program and accelerate <emphasis>basic linear algebra subprograms</emphasis> (BLAS) on top of <ulink url="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</ulink>.</para>
<para><image type="html" name="LinearAlgebra.png" width="50%"></image>
</para>
<sect1 id="LinearAlgebracublasFlowCapturer_1WhatIsBLAS">
<title>What is BLAS?</title>
<para>The BLAS (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations. There are three levels:</para>
<para><orderedlist>
<listitem><para>Level 1: performs scalar, vector, and vector-vector operations</para>
</listitem><listitem><para>Level 2: performs matrix-vector operations</para>
</listitem><listitem><para>Level 3: performs matrix-matrix operations</para>
</listitem></orderedlist>
</para>
<para>BLAS is commonly used by linear algebra software. The <ulink url="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</ulink> library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the NVIDIA CUDA runtime and it allows users to access the computational resources of NVIDIA GPUs.</para>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1HowToUsecublasFlowCapturer">
<title>What is a cublasFlow Capturer? Why?</title>
<para><ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> provides an interface over native cuBLAS functions and allows users to express linear algebra algorithms using a <emphasis>task graph model</emphasis>. We transform the task graph into a CUDA graph using a stream capture algorithm optimized for maximum concurrency. When a cuBLAS program is transformed into a CUDA graph, we can launch the entire graph using a single kernel call to largely reduce the kernel call overheads and efficiently overlap concurrent kernels. This organization is particularly suitable for large linear algebra programs that contain hundreds of cuBLAS operations.</para>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1DataModelOscublasFlowCapturer">
<title>Understand the Data Model</title>
<para>The data pointers used within <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> must sit in GPU memory space, including scalar pointers (<computeroutput>alpha</computeroutput> and <computeroutput>beta</computeroutput>), input pointers (e.g., vectors, matrices), and output pointers (e.g., result). By default, we set the pointer mode to <computeroutput>CUBLAS_POINTER_MODE_DEVICE</computeroutput>. You must allocate required matrices and vectors in the GPU memory space, fill them with data, call the methods defined in <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref>, and then upload the results from GPU memory space back to the host.</para>
<para><simplesect kind="note"><para><ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> currently supports only <computeroutput>float</computeroutput> and <computeroutput>double</computeroutput> data types.</para>
</simplesect>
The cuBLAS library uses <emphasis>column-major storage</emphasis> and 1-based indexing. Since C/C++ adopts row-major storage, we cannot use the native array semantics when matrix-matrix or matrix-vector operations are involved. We often need extra transposition on input matrices before these operations can take place correctly. In terms of storage, a row-major matrix is equivalent to a transposed column-major matrix, as shown below:</para>
<para><formula id="0">\[ A_{RowMajor} \iff A^T_{ColumnMajor} \]</formula></para>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerLevel-1">
<title>Use Level-1 Methods</title>
<para>We currently support the following level-1 methods:</para>
<para><itemizedlist>
<listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1ab1357bb1728f5fe526acef8afee7111e" kindref="member">tf::cublasFlowCapturer::amax</ref> finds the smallest element index of the maximum absolute magnitude over a vector</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a7a6485c37d50b9c79205f728ab380929" kindref="member">tf::cublasFlowCapturer::amin</ref> finds the smallest element index of the minimum absolute magnitude over a vector</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1ab7672cee3d219ccc75c48b62cf1d1bad" kindref="member">tf::cublasFlowCapturer::asum</ref> computes the sum of absolute values of elements over a vector</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a56f8649d43652597da1c9b0a5f88b0ee" kindref="member">tf::cublasFlowCapturer::axpy</ref> multiplies a vector by a scalar and adds it to another vector</para>
</listitem><listitem><para><ref refid="classtf_1_1cudaFlowCapturerBase_1a9fd8983c782f841bba6b10de39becdf6" kindref="member">tf::cublasFlowCapturer::copy</ref> copies a vector into another vector</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1afdfa01d9f277051e44d7ed9663555b52" kindref="member">tf::cublasFlowCapturer::dot</ref> computes the dot product of two vectors</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a8000fc6dbbb6f6f5a033f1b365e80d38" kindref="member">tf::cublasFlowCapturer::nrm2</ref> computes the Euclidean norm of a vector</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1adb8f5d3137f5ccb3469a5bdde454a8bf" kindref="member">tf::cublasFlowCapturer::scal</ref> multiples a vector by a scalar</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a32451b05fd7eb937ce8e807b5d5abe1f" kindref="member">tf::cublasFlowCapturer::swap</ref> interchanges the elements of two vectors</para>
</listitem></itemizedlist>
</para>
<para>Our level-1 methods capture the native <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-1-function-reference">cublas level-1 calls</ulink> with internal stream(s) optimized for maximum concurrency.</para>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerLeve2-1">
<title>Use Level-2 Methods</title>
<para>We currently support the following level-2 methods:</para>
<para><itemizedlist>
<listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a72185bf94321948b5b3657cc9c52ad0a" kindref="member">tf::cublasFlowCapturer::gemv</ref> performs general matrix-vector multiplication</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a756dc6637521ef4f2249711effd1d0f5" kindref="member">tf::cublasFlowCapturer::c_geam</ref> performs general matrix-vector multiplication on C-styled row-major layout</para>
</listitem></itemizedlist>
</para>
<para>Our level-2 methods capture the native <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">cublas level-2 calls</ulink> with internal stream(s) optimized for maximum concurrency.</para>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerLevel-3">
<title>Use Level-3 Methods</title>
<para>We currently support the following level-3 methods:</para>
<para><itemizedlist>
<listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a30b437e511b5719f6253d3a9cf0a992c" kindref="member">tf::cublasFlowCapturer::geam</ref> performs matrix-matrix addition/transposition</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a756dc6637521ef4f2249711effd1d0f5" kindref="member">tf::cublasFlowCapturer::c_geam</ref> performs matrix-matrix addition/transposition on C-styled row-major storage</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a8adbe06476f146b27bb00ba6054e5879" kindref="member">tf::cublasFlowCapturer::gemm</ref> performs general matrix-matrix multiplication</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1aecfd3b623b457d277dca40c2e1b3c1c0" kindref="member">tf::cublasFlowCapturer::c_gemm</ref> performs general matrix-matrix multiplication on C-styled row-major storage</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a56af0e8ed80e5626fe2f594608afa405" kindref="member">tf::cublasFlowCapturer::gemm_batched</ref> performs batched general matrix-matrix multiplication</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1aa9415957e3e48df65dc3baad86d05b38" kindref="member">tf::cublasFlowCapturer::c_gemm_batched</ref> performs batched general matrix-matrix multiplication on C-styled row-major storage</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1a36ecdcea0f24575187e44374e583df2e" kindref="member">tf::cublasFlowCapturer::gemm_sbatched</ref> performs batched general matrix-matrix multiplication with strided memory access</para>
</listitem><listitem><para><ref refid="classtf_1_1cublasFlowCapturer_1ae57c53a1a07c0b4f73d90bf21fee4e1c" kindref="member">tf::cublasFlowCapturer::c_gemm_sbatched</ref> performs batched general matrix-matrix multiplication with strided memory access on C-styled row-major storage</para>
</listitem></itemizedlist>
</para>
<para>Our level-3 methods capture the native <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">cublas level-3 calls</ulink> and <ulink url="https://docs.nvidia.com/cuda/cublas/index.html#blas-like-extension">cublas-extension calls</ulink> with internal stream(s) optimized for maximum concurrency.</para>
</sect1>
<sect1 id="LinearAlgebracublasFlowCapturer_1cublasFlowCapturerExtension">
<title>Extend to Other cuBLAS Methods</title>
<para><ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> is derived from <ref refid="classtf_1_1cudaFlowCapturerBase" kindref="compound">tf::cudaFlowCapturerBase</ref> and is created from a factory interface <ref refid="classtf_1_1cudaFlowCapturer_1a49dd9727aeb5bccd7d826c6b11a6882d" kindref="member">tf::cudaFlowCapturer::make_capturer</ref>. This design enables a <emphasis>flat</emphasis> flow graph that combines the advantages of <ref refid="classtf_1_1cudaFlowCapturer" kindref="compound">tf::cudaFlowCapturer</ref> and <ref refid="classtf_1_1cublasFlowCapturer" kindref="compound">tf::cublasFlowCapturer</ref> for users to efficiently create large linear algebra applications. </para>
</sect1>
    </detaileddescription>
  </compounddef>
</doxygen>
