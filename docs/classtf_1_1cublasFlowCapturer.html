<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Taskflow Handbook</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="taskflow.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname"><a href="https://taskflow.github.io/">Taskflow</a>
   &#160;<span id="projectnumber">3.0.0-Master-Branch</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classtf_1_1cublasFlowCapturer.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classtf_1_1cublasFlowCapturer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">tf::cublasFlowCapturer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>class object to construct a cuBLAS task graph  
 <a href="classtf_1_1cublasFlowCapturer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="cublas__flow_8hpp_source.html">cublas_flow.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for tf::cublasFlowCapturer:</div>
<div class="dyncontent">
<div class="center"><img src="classtf_1_1cublasFlowCapturer__inherit__graph.png" border="0" usemap="#tf_1_1cublasFlowCapturer_inherit__map" alt="Inheritance graph"/></div>
<map name="tf_1_1cublasFlowCapturer_inherit__map" id="tf_1_1cublasFlowCapturer_inherit__map">
<area shape="rect" id="node2" href="classtf_1_1cudaFlowCapturerBase.html" title="base class to construct a CUDA task graph through stream capture " alt="" coords="5,5,181,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for tf::cublasFlowCapturer:</div>
<div class="dyncontent">
<div class="center"><img src="classtf_1_1cublasFlowCapturer__coll__graph.png" border="0" usemap="#tf_1_1cublasFlowCapturer_coll__map" alt="Collaboration graph"/></div>
<map name="tf_1_1cublasFlowCapturer_coll__map" id="tf_1_1cublasFlowCapturer_coll__map">
<area shape="rect" id="node2" href="classtf_1_1cudaFlowCapturerBase.html" title="base class to construct a CUDA task graph through stream capture " alt="" coords="5,5,181,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:acd81da28696e8b1efb2bb45058a2f0e3"><td class="memItemLeft" align="right" valign="top"><a id="acd81da28696e8b1efb2bb45058a2f0e3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#acd81da28696e8b1efb2bb45058a2f0e3">cublasFlowCapturer</a> ()=default</td></tr>
<tr class="memdesc:acd81da28696e8b1efb2bb45058a2f0e3"><td class="mdescLeft">&#160;</td><td class="mdescRight">constructs a cublas flow capturer <br /></td></tr>
<tr class="separator:acd81da28696e8b1efb2bb45058a2f0e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2701b05226ef193e45482c1bb56f93de"><td class="memItemLeft" align="right" valign="top">cublasHandle_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a2701b05226ef193e45482c1bb56f93de">native_handle</a> ()</td></tr>
<tr class="memdesc:a2701b05226ef193e45482c1bb56f93de"><td class="mdescLeft">&#160;</td><td class="mdescRight">gets the native cublas handle associated with this cublasFlowCapturer  <a href="#a2701b05226ef193e45482c1bb56f93de">More...</a><br /></td></tr>
<tr class="separator:a2701b05226ef193e45482c1bb56f93de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e5d2a2502fcfe0094d5ac354995cb71"><td class="memTemplParams" colspan="2">template&lt;typename T , std::enable_if_t&lt;!std::is_same_v&lt; T, void &gt;, void &gt; *  = nullptr&gt; </td></tr>
<tr class="memitem:a5e5d2a2502fcfe0094d5ac354995cb71"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a5e5d2a2502fcfe0094d5ac354995cb71">vset</a> (size_t n, const T *h, int inch, T *d, int incd)</td></tr>
<tr class="memdesc:a5e5d2a2502fcfe0094d5ac354995cb71"><td class="mdescLeft">&#160;</td><td class="mdescRight">copies vector data from host to device  <a href="#a5e5d2a2502fcfe0094d5ac354995cb71">More...</a><br /></td></tr>
<tr class="separator:a5e5d2a2502fcfe0094d5ac354995cb71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8f5052cbe1203d6ee3d3d40dffbb8eb"><td class="memTemplParams" colspan="2">template&lt;typename T , std::enable_if_t&lt;!std::is_same_v&lt; T, void &gt;, void &gt; *  = nullptr&gt; </td></tr>
<tr class="memitem:af8f5052cbe1203d6ee3d3d40dffbb8eb"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#af8f5052cbe1203d6ee3d3d40dffbb8eb">vget</a> (size_t n, const T *d, int incd, T *h, int inch)</td></tr>
<tr class="memdesc:af8f5052cbe1203d6ee3d3d40dffbb8eb"><td class="mdescLeft">&#160;</td><td class="mdescRight">copies vector data from device to host  <a href="#af8f5052cbe1203d6ee3d3d40dffbb8eb">More...</a><br /></td></tr>
<tr class="separator:af8f5052cbe1203d6ee3d3d40dffbb8eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1357bb1728f5fe526acef8afee7111e"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ab1357bb1728f5fe526acef8afee7111e"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#ab1357bb1728f5fe526acef8afee7111e">amax</a> (int n, const T *x, int incx, int *result)</td></tr>
<tr class="memdesc:ab1357bb1728f5fe526acef8afee7111e"><td class="mdescLeft">&#160;</td><td class="mdescRight">finds the smallest index of the element of the maximum absolute magnitude  <a href="#ab1357bb1728f5fe526acef8afee7111e">More...</a><br /></td></tr>
<tr class="separator:ab1357bb1728f5fe526acef8afee7111e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a6485c37d50b9c79205f728ab380929"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a7a6485c37d50b9c79205f728ab380929"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a7a6485c37d50b9c79205f728ab380929">amin</a> (int n, const T *x, int incx, int *result)</td></tr>
<tr class="memdesc:a7a6485c37d50b9c79205f728ab380929"><td class="mdescLeft">&#160;</td><td class="mdescRight">finds the smallest index of the element of the minimum absolute magnitude  <a href="#a7a6485c37d50b9c79205f728ab380929">More...</a><br /></td></tr>
<tr class="separator:a7a6485c37d50b9c79205f728ab380929"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7672cee3d219ccc75c48b62cf1d1bad"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ab7672cee3d219ccc75c48b62cf1d1bad"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#ab7672cee3d219ccc75c48b62cf1d1bad">asum</a> (int n, const T *x, int incx, T *result)</td></tr>
<tr class="memdesc:ab7672cee3d219ccc75c48b62cf1d1bad"><td class="mdescLeft">&#160;</td><td class="mdescRight">finds the sum of absolute values of the elements over a vector  <a href="#ab7672cee3d219ccc75c48b62cf1d1bad">More...</a><br /></td></tr>
<tr class="separator:ab7672cee3d219ccc75c48b62cf1d1bad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56f8649d43652597da1c9b0a5f88b0ee"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a56f8649d43652597da1c9b0a5f88b0ee"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a56f8649d43652597da1c9b0a5f88b0ee">axpy</a> (int n, const T *alpha, const T *x, int incx, T *y, int incy)</td></tr>
<tr class="memdesc:a56f8649d43652597da1c9b0a5f88b0ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">multiples a vector by a scalar and adds it to a vector  <a href="#a56f8649d43652597da1c9b0a5f88b0ee">More...</a><br /></td></tr>
<tr class="separator:a56f8649d43652597da1c9b0a5f88b0ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af315b411bcaa2bd2bc1436f7f2ca5e21"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:af315b411bcaa2bd2bc1436f7f2ca5e21"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#af315b411bcaa2bd2bc1436f7f2ca5e21">vcopy</a> (int n, const T *x, int incx, T *y, int incy)</td></tr>
<tr class="memdesc:af315b411bcaa2bd2bc1436f7f2ca5e21"><td class="mdescLeft">&#160;</td><td class="mdescRight">copies a vector to another vector  <a href="#af315b411bcaa2bd2bc1436f7f2ca5e21">More...</a><br /></td></tr>
<tr class="separator:af315b411bcaa2bd2bc1436f7f2ca5e21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdfa01d9f277051e44d7ed9663555b52"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:afdfa01d9f277051e44d7ed9663555b52"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#afdfa01d9f277051e44d7ed9663555b52">dot</a> (int n, const T *x, int incx, const T *y, int incy, T *result)</td></tr>
<tr class="memdesc:afdfa01d9f277051e44d7ed9663555b52"><td class="mdescLeft">&#160;</td><td class="mdescRight">computes the dot product of two vectors  <a href="#afdfa01d9f277051e44d7ed9663555b52">More...</a><br /></td></tr>
<tr class="separator:afdfa01d9f277051e44d7ed9663555b52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8000fc6dbbb6f6f5a033f1b365e80d38"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a8000fc6dbbb6f6f5a033f1b365e80d38"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a8000fc6dbbb6f6f5a033f1b365e80d38">nrm2</a> (int n, const T *x, int incx, T *result)</td></tr>
<tr class="memdesc:a8000fc6dbbb6f6f5a033f1b365e80d38"><td class="mdescLeft">&#160;</td><td class="mdescRight">computes the Euclidean norm of a vector  <a href="#a8000fc6dbbb6f6f5a033f1b365e80d38">More...</a><br /></td></tr>
<tr class="separator:a8000fc6dbbb6f6f5a033f1b365e80d38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb8f5d3137f5ccb3469a5bdde454a8bf"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:adb8f5d3137f5ccb3469a5bdde454a8bf"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#adb8f5d3137f5ccb3469a5bdde454a8bf">scal</a> (int n, const T *scalar, T *x, int incx)</td></tr>
<tr class="memdesc:adb8f5d3137f5ccb3469a5bdde454a8bf"><td class="mdescLeft">&#160;</td><td class="mdescRight">scales a vector by a scalar  <a href="#adb8f5d3137f5ccb3469a5bdde454a8bf">More...</a><br /></td></tr>
<tr class="separator:adb8f5d3137f5ccb3469a5bdde454a8bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32451b05fd7eb937ce8e807b5d5abe1f"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a32451b05fd7eb937ce8e807b5d5abe1f"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a32451b05fd7eb937ce8e807b5d5abe1f">swap</a> (int n, T *x, int incx, T *y, int incy)</td></tr>
<tr class="memdesc:a32451b05fd7eb937ce8e807b5d5abe1f"><td class="mdescLeft">&#160;</td><td class="mdescRight">swaps elements between two vectors  <a href="#a32451b05fd7eb937ce8e807b5d5abe1f">More...</a><br /></td></tr>
<tr class="separator:a32451b05fd7eb937ce8e807b5d5abe1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72185bf94321948b5b3657cc9c52ad0a"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a72185bf94321948b5b3657cc9c52ad0a"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a72185bf94321948b5b3657cc9c52ad0a">gemv</a> (cublasOperation_t trans, int m, int n, const T *alpha, const T *A, int lda, const T *x, int incx, const T *beta, T *y, int incy)</td></tr>
<tr class="memdesc:a72185bf94321948b5b3657cc9c52ad0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">performs matrix-vector multiplication  <a href="#a72185bf94321948b5b3657cc9c52ad0a">More...</a><br /></td></tr>
<tr class="separator:a72185bf94321948b5b3657cc9c52ad0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a492f3f22949e0e6b1058113eb475d0"><td class="memTemplParams" colspan="2"><a id="a3a492f3f22949e0e6b1058113eb475d0"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a3a492f3f22949e0e6b1058113eb475d0"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a3a492f3f22949e0e6b1058113eb475d0">c_gemv</a> (cublasOperation_t trans, int m, int n, const T *alpha, const T *A, int lda, const T *x, int incx, const T *beta, T *y, int incy)</td></tr>
<tr class="memdesc:a3a492f3f22949e0e6b1058113eb475d0"><td class="mdescLeft">&#160;</td><td class="mdescRight">similar to <a class="el" href="classtf_1_1cublasFlowCapturer.html#a72185bf94321948b5b3657cc9c52ad0a" title="performs matrix-vector multiplication ">tf::cublasFlowCapturer::gemv</a> but operates on C-styled row-major layout <br /></td></tr>
<tr class="separator:a3a492f3f22949e0e6b1058113eb475d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30b437e511b5719f6253d3a9cf0a992c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a30b437e511b5719f6253d3a9cf0a992c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a30b437e511b5719f6253d3a9cf0a992c">geam</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, const T *alpha, const T *A, int lda, const T *beta, const T *B, int ldb, T *C, int ldc)</td></tr>
<tr class="memdesc:a30b437e511b5719f6253d3a9cf0a992c"><td class="mdescLeft">&#160;</td><td class="mdescRight">performs matrix-matrix addition and transposition  <a href="#a30b437e511b5719f6253d3a9cf0a992c">More...</a><br /></td></tr>
<tr class="separator:a30b437e511b5719f6253d3a9cf0a992c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a756dc6637521ef4f2249711effd1d0f5"><td class="memTemplParams" colspan="2"><a id="a756dc6637521ef4f2249711effd1d0f5"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a756dc6637521ef4f2249711effd1d0f5"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a756dc6637521ef4f2249711effd1d0f5">c_geam</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, const T *alpha, const T *A, int lda, const T *beta, const T *B, int ldb, T *C, int ldc)</td></tr>
<tr class="memdesc:a756dc6637521ef4f2249711effd1d0f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">similar to <a class="el" href="classtf_1_1cublasFlowCapturer.html#a30b437e511b5719f6253d3a9cf0a992c" title="performs matrix-matrix addition and transposition ">tf::cublasFlowCapturer::geam</a> but on row-major layout <br /></td></tr>
<tr class="separator:a756dc6637521ef4f2249711effd1d0f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8adbe06476f146b27bb00ba6054e5879"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a8adbe06476f146b27bb00ba6054e5879"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a8adbe06476f146b27bb00ba6054e5879">gemm</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, int k, const T *alpha, const T *A, int lda, const T *B, int ldb, const T *beta, T *C, int ldc)</td></tr>
<tr class="memdesc:a8adbe06476f146b27bb00ba6054e5879"><td class="mdescLeft">&#160;</td><td class="mdescRight">performs matrix-matrix multiplication  <a href="#a8adbe06476f146b27bb00ba6054e5879">More...</a><br /></td></tr>
<tr class="separator:a8adbe06476f146b27bb00ba6054e5879"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecfd3b623b457d277dca40c2e1b3c1c0"><td class="memTemplParams" colspan="2"><a id="aecfd3b623b457d277dca40c2e1b3c1c0"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:aecfd3b623b457d277dca40c2e1b3c1c0"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#aecfd3b623b457d277dca40c2e1b3c1c0">c_gemm</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, int k, const T *alpha, const T *A, int lda, const T *B, int ldb, const T *beta, T *C, int ldc)</td></tr>
<tr class="memdesc:aecfd3b623b457d277dca40c2e1b3c1c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">similar to <a class="el" href="classtf_1_1cublasFlowCapturer.html#a8adbe06476f146b27bb00ba6054e5879" title="performs matrix-matrix multiplication ">tf::cublasFlowCapturer::gemm</a> but operates on C-styled row-major layout <br /></td></tr>
<tr class="separator:aecfd3b623b457d277dca40c2e1b3c1c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56af0e8ed80e5626fe2f594608afa405"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a56af0e8ed80e5626fe2f594608afa405"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a56af0e8ed80e5626fe2f594608afa405">gemm_batched</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, int k, const T *alpha, const T *A[], int lda, const T *B[], int ldb, const T *beta, T *C[], int ldc, int bc)</td></tr>
<tr class="memdesc:a56af0e8ed80e5626fe2f594608afa405"><td class="mdescLeft">&#160;</td><td class="mdescRight">performs matrix-matrix multiplication over a batch of matrices  <a href="#a56af0e8ed80e5626fe2f594608afa405">More...</a><br /></td></tr>
<tr class="separator:a56af0e8ed80e5626fe2f594608afa405"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9415957e3e48df65dc3baad86d05b38"><td class="memTemplParams" colspan="2"><a id="aa9415957e3e48df65dc3baad86d05b38"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:aa9415957e3e48df65dc3baad86d05b38"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#aa9415957e3e48df65dc3baad86d05b38">c_gemm_batched</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, int k, const T *alpha, const T *A[], int lda, const T *B[], int ldb, const T *beta, T *C[], int ldc, int bc)</td></tr>
<tr class="memdesc:aa9415957e3e48df65dc3baad86d05b38"><td class="mdescLeft">&#160;</td><td class="mdescRight">similar to <a class="el" href="classtf_1_1cublasFlowCapturer.html#a56af0e8ed80e5626fe2f594608afa405" title="performs matrix-matrix multiplication over a batch of matrices ">tf::cublasFlowCapturer::gemm_batched</a> but operates on C-styled row-major layout <br /></td></tr>
<tr class="separator:aa9415957e3e48df65dc3baad86d05b38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36ecdcea0f24575187e44374e583df2e"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a36ecdcea0f24575187e44374e583df2e"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#a36ecdcea0f24575187e44374e583df2e">gemm_sbatched</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, int k, const T *alpha, const T *A, int lda, long long int sA, const T *B, int ldb, long long int sB, const T *beta, T *C, int ldc, long long int sC, int bc)</td></tr>
<tr class="memdesc:a36ecdcea0f24575187e44374e583df2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">performs matrix-matrix multiplication over a batch of matrices with strided memory access  <a href="#a36ecdcea0f24575187e44374e583df2e">More...</a><br /></td></tr>
<tr class="separator:a36ecdcea0f24575187e44374e583df2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae57c53a1a07c0b4f73d90bf21fee4e1c"><td class="memTemplParams" colspan="2"><a id="ae57c53a1a07c0b4f73d90bf21fee4e1c"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae57c53a1a07c0b4f73d90bf21fee4e1c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cublasFlowCapturer.html#ae57c53a1a07c0b4f73d90bf21fee4e1c">c_gemm_sbatched</a> (cublasOperation_t ta, cublasOperation_t tb, int m, int n, int k, const T *alpha, const T *A, int lda, long long int sA, const T *B, int ldb, long long int sB, const T *beta, T *C, int ldc, long long int sC, int bc)</td></tr>
<tr class="memdesc:ae57c53a1a07c0b4f73d90bf21fee4e1c"><td class="mdescLeft">&#160;</td><td class="mdescRight">similar to <a class="el" href="classtf_1_1cublasFlowCapturer.html#ae57c53a1a07c0b4f73d90bf21fee4e1c" title="similar to tf::cublasFlowCapturer::c_gemm_sbatched but operates on C-styled row-major layout ...">tf::cublasFlowCapturer::c_gemm_sbatched</a> but operates on C-styled row-major layout <br /></td></tr>
<tr class="separator:ae57c53a1a07c0b4f73d90bf21fee4e1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classtf_1_1cudaFlowCapturerBase"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classtf_1_1cudaFlowCapturerBase')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classtf_1_1cudaFlowCapturerBase.html">tf::cudaFlowCapturerBase</a></td></tr>
<tr class="memitem:a43739b92f51358bd144270664c6fdf8e inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memItemLeft" align="right" valign="top"><a id="a43739b92f51358bd144270664c6fdf8e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a43739b92f51358bd144270664c6fdf8e">cudaFlowCapturerBase</a> ()=default</td></tr>
<tr class="memdesc:a43739b92f51358bd144270664c6fdf8e inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">default constructor <br /></td></tr>
<tr class="separator:a43739b92f51358bd144270664c6fdf8e inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09d58616acdfe01dfe09271f8b3587ff inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memItemLeft" align="right" valign="top"><a id="a09d58616acdfe01dfe09271f8b3587ff"></a>
virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a09d58616acdfe01dfe09271f8b3587ff">~cudaFlowCapturerBase</a> ()=default</td></tr>
<tr class="memdesc:a09d58616acdfe01dfe09271f8b3587ff inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">default virtual destructor <br /></td></tr>
<tr class="separator:a09d58616acdfe01dfe09271f8b3587ff inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf651356def71f613c589c29588398c2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename C &gt; </td></tr>
<tr class="memitem:adf651356def71f613c589c29588398c2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#adf651356def71f613c589c29588398c2">on</a> (C &amp;&amp;callable)</td></tr>
<tr class="memdesc:adf651356def71f613c589c29588398c2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">captures a sequential CUDA operations from the given callable  <a href="classtf_1_1cudaFlowCapturerBase.html#adf651356def71f613c589c29588398c2">More...</a><br /></td></tr>
<tr class="separator:adf651356def71f613c589c29588398c2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38adf66dfcc0829708db653d153a83e2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a38adf66dfcc0829708db653d153a83e2">memcpy</a> (void *dst, const void *src, size_t count)</td></tr>
<tr class="memdesc:a38adf66dfcc0829708db653d153a83e2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">copies data between host and device asynchronously through a stream  <a href="classtf_1_1cudaFlowCapturerBase.html#a38adf66dfcc0829708db653d153a83e2">More...</a><br /></td></tr>
<tr class="separator:a38adf66dfcc0829708db653d153a83e2 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9fd8983c782f841bba6b10de39becdf6 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename T , std::enable_if_t&lt;!std::is_same_v&lt; T, void &gt;, void &gt; *  = nullptr&gt; </td></tr>
<tr class="memitem:a9fd8983c782f841bba6b10de39becdf6 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a9fd8983c782f841bba6b10de39becdf6">copy</a> (T *tgt, const T *src, size_t num)</td></tr>
<tr class="memdesc:a9fd8983c782f841bba6b10de39becdf6 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">captures a copy task of typed data  <a href="classtf_1_1cudaFlowCapturerBase.html#a9fd8983c782f841bba6b10de39becdf6">More...</a><br /></td></tr>
<tr class="separator:a9fd8983c782f841bba6b10de39becdf6 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e3071171c0875c93dcc077a2e0a435a inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a8e3071171c0875c93dcc077a2e0a435a">memset</a> (void *devPtr, int value, size_t count)</td></tr>
<tr class="memdesc:a8e3071171c0875c93dcc077a2e0a435a inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">initializes or sets GPU memory to the given value byte by byte  <a href="classtf_1_1cudaFlowCapturerBase.html#a8e3071171c0875c93dcc077a2e0a435a">More...</a><br /></td></tr>
<tr class="separator:a8e3071171c0875c93dcc077a2e0a435a inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad836d32cc2e9532ce57fe3ad6cc67d5d inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename F , typename... ArgsT&gt; </td></tr>
<tr class="memitem:ad836d32cc2e9532ce57fe3ad6cc67d5d inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#ad836d32cc2e9532ce57fe3ad6cc67d5d">kernel</a> (dim3 g, dim3 b, size_t s, F &amp;&amp;f, ArgsT &amp;&amp;... args)</td></tr>
<tr class="memdesc:ad836d32cc2e9532ce57fe3ad6cc67d5d inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">captures a kernel  <a href="classtf_1_1cudaFlowCapturerBase.html#ad836d32cc2e9532ce57fe3ad6cc67d5d">More...</a><br /></td></tr>
<tr class="separator:ad836d32cc2e9532ce57fe3ad6cc67d5d inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac25236625772a0a2c66831517b9ec288 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename C &gt; </td></tr>
<tr class="memitem:ac25236625772a0a2c66831517b9ec288 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#ac25236625772a0a2c66831517b9ec288">single_task</a> (C &amp;&amp;callable)</td></tr>
<tr class="memdesc:ac25236625772a0a2c66831517b9ec288 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">capturers a kernel to runs the given callable with only one thread  <a href="classtf_1_1cudaFlowCapturerBase.html#ac25236625772a0a2c66831517b9ec288">More...</a><br /></td></tr>
<tr class="separator:ac25236625772a0a2c66831517b9ec288 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a583e4df1139cf6f20b6e79dfde977a51 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename I , typename C &gt; </td></tr>
<tr class="memitem:a583e4df1139cf6f20b6e79dfde977a51 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a583e4df1139cf6f20b6e79dfde977a51">for_each</a> (I first, I last, C &amp;&amp;callable)</td></tr>
<tr class="memdesc:a583e4df1139cf6f20b6e79dfde977a51 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">captures a kernel that applies a callable to each dereferenced element of the data array  <a href="classtf_1_1cudaFlowCapturerBase.html#a583e4df1139cf6f20b6e79dfde977a51">More...</a><br /></td></tr>
<tr class="separator:a583e4df1139cf6f20b6e79dfde977a51 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0320596ee37d68cfce5746027ebc97de inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename I , typename C &gt; </td></tr>
<tr class="memitem:a0320596ee37d68cfce5746027ebc97de inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a0320596ee37d68cfce5746027ebc97de">for_each_index</a> (I first, I last, I step, C &amp;&amp;callable)</td></tr>
<tr class="memdesc:a0320596ee37d68cfce5746027ebc97de inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">captures a kernel that applies a callable to each index in the range with the step size  <a href="classtf_1_1cudaFlowCapturerBase.html#a0320596ee37d68cfce5746027ebc97de">More...</a><br /></td></tr>
<tr class="separator:a0320596ee37d68cfce5746027ebc97de inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44fb0c626c46de1bb95369e33194f5c7 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplParams" colspan="2">template&lt;typename I , typename C , typename... S&gt; </td></tr>
<tr class="memitem:a44fb0c626c46de1bb95369e33194f5c7 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classtf_1_1cudaFlowCapturerBase.html#a44fb0c626c46de1bb95369e33194f5c7">transform</a> (I first, I last, C &amp;&amp;callable, S... srcs)</td></tr>
<tr class="memdesc:a44fb0c626c46de1bb95369e33194f5c7 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">captures a kernel that applies a callable to a source range and stores the result in a target range  <a href="classtf_1_1cudaFlowCapturerBase.html#a44fb0c626c46de1bb95369e33194f5c7">More...</a><br /></td></tr>
<tr class="separator:a44fb0c626c46de1bb95369e33194f5c7 inherit pub_methods_classtf_1_1cudaFlowCapturerBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>class object to construct a cuBLAS task graph </p>
<p>cublasFlowCapturer provides a higher-level interface over the <a href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a> library and hide concurrency details from users. It inherits methods from <a class="el" href="classtf_1_1cudaFlowCapturerBase.html" title="base class to construct a CUDA task graph through stream capture ">tf::cudaFlowCapturerBase</a> and must be used from a <a class="el" href="classtf_1_1cudaFlowCapturer.html" title="class for building a CUDA task dependency graph through stream capture ">tf::cudaFlowCapturer</a> object. All pointers used to cublasFlowCapturer methods must be in GPU memory space or managed (i.e., <code>cudaMallocManaged</code>), including scalars, <code>alpha</code> and <code>beta</code>, input data and output data pointers. The following example uses <code>cublas&lt;t&gt;amax</code> to find the minimum index of the element of the maximum absolute magnitude in a vector.</p>
<div class="fragment"><div class="line"><a class="code" href="classtf_1_1Executor.html">tf::Executor</a> executor;</div><div class="line"><a class="code" href="classtf_1_1Taskflow.html">tf::Taskflow</a> taskflow;</div><div class="line"></div><div class="line"><span class="keywordtype">size_t</span> N = 1024;</div><div class="line"><span class="keywordtype">float</span> *x = <span class="keyword">nullptr</span>;</div><div class="line"><span class="keywordtype">int</span> *d_res;</div><div class="line"><span class="keywordtype">int</span>  h_res;</div><div class="line"></div><div class="line"><a class="codeRef" doxygen="/Users/luan/taskflow/doxygen/cppreference-doxygen-web.tag.xml:http://en.cppreference.com/w/" href="http://en.cppreference.com/w/cpp/container/vector.html">std::vector&lt;float&gt;</a> host(N, 0.0f);</div><div class="line">host[512] = 100.0f;  <span class="comment">// artificially set the mid-position to the largest</span></div><div class="line"></div><div class="line">cudaMalloc(&amp;x, N*<span class="keyword">sizeof</span>(<span class="keywordtype">float</span>));</div><div class="line">cudaMalloc(&amp;d_res, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));</div><div class="line"></div><div class="line">taskflow.<a class="code" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code" href="classtf_1_1cudaFlowCapturer.html">tf::cudaFlowCapturer</a>&amp; capturer){</div><div class="line">  <a class="code" href="classtf_1_1cublasFlowCapturer.html">tf::cublasFlowCapturer</a>* cublas = capturer.<a class="code" href="classtf_1_1cudaFlowCapturer.html#a49dd9727aeb5bccd7d826c6b11a6882d">make_capturer</a>&lt;<a class="code" href="classtf_1_1cublasFlowCapturer.html">tf::cublasFlowCapturer</a>&gt;();</div><div class="line"></div><div class="line">  <a class="code" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d      = capturer.<a class="code" href="classtf_1_1cudaFlowCapturerBase.html#a9fd8983c782f841bba6b10de39becdf6">copy</a>(x, host.data(), N);</div><div class="line">  <a class="code" href="classtf_1_1cudaTask.html">tf::cudaTask</a> find_max = cublas-&gt;<a class="code" href="classtf_1_1cublasFlowCapturer.html#ab1357bb1728f5fe526acef8afee7111e">amax</a>(N, x, 1, d_res);  </div><div class="line">  <a class="code" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h      = capturer.<a class="code" href="classtf_1_1cudaFlowCapturerBase.html#a9fd8983c782f841bba6b10de39becdf6">copy</a>(&amp;h_res, d_res, 1);</div><div class="line">  </div><div class="line">  h2d.<a class="code" href="classtf_1_1cudaTask.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(find_max);  <span class="comment">// amax runs before host-to-device copy</span></div><div class="line">  find_max.<a class="code" href="classtf_1_1cudaTask.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(d2h);  <span class="comment">// amax runs after  device-to-host copy</span></div><div class="line">});</div><div class="line"></div><div class="line">executor.<a class="code" href="classtf_1_1Executor.html#a81f35d5b0a20ac0646447eb80d97c0aa">run</a>(taskflow).wait();</div><div class="line"></div><div class="line">assert(h_res == 512);</div></div><!-- fragment --><p>Currently, cublasFlowCapturer supports only <code>float</code> and <code>double</code> data types.</p>
<p>Please refer to <a href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a> for more details. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="ab1357bb1728f5fe526acef8afee7111e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1357bb1728f5fe526acef8afee7111e">&#9670;&nbsp;</a></span>amax()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::amax </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>finds the smallest index of the element of the maximum absolute magnitude </p>
<p>This method calls native <code>cublas&lt;t&gt;amax</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements in vector <code>x</code> </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">result</td><td>the resulting index (1-based indexing)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a7a6485c37d50b9c79205f728ab380929"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a6485c37d50b9c79205f728ab380929">&#9670;&nbsp;</a></span>amin()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::amin </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>finds the smallest index of the element of the minimum absolute magnitude </p>
<p>This method calls native <code>cublas&lt;t&gt;amin</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements in vector <code>x</code> </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">result</td><td>the resulting index (1-based indexing)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="ab7672cee3d219ccc75c48b62cf1d1bad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab7672cee3d219ccc75c48b62cf1d1bad">&#9670;&nbsp;</a></span>asum()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::asum </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>finds the sum of absolute values of the elements over a vector </p>
<p>This method calls native <code>cublas&lt;t&gt;asum</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements in vector <code>x</code> </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">result</td><td>the result</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a56f8649d43652597da1c9b0a5f88b0ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56f8649d43652597da1c9b0a5f88b0ee">&#9670;&nbsp;</a></span>axpy()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::axpy </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>multiples a vector by a scalar and adds it to a vector </p>
<p>This function multiplies the vector <code>x</code> by the scalar <code>alpha</code> and adds it to the vector <code>y</code> overwriting the latest vector with the result. Hence, the performed operation is:</p>
<p><code>y[j] = alpha * x[k] + y[j]</code>,</p>
<p>where <code>j</code> and <code>k</code> are indices of <code>n</code> elements with step sizes <code>incy</code> and <code>incx</code>.</p>
<p>This method calls native <code>cublas&lt;t&gt;asum</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements in vectors <code>x</code> and <code>y</code> </td></tr>
    <tr><td class="paramname">alpha</td><td>scalar used to multiplication </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector <code>x</code> </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">y</td><td>pointer to the memory address of the vector <code>y</code> </td></tr>
    <tr><td class="paramname">incy</td><td>stride between consecutive elements of <code>y</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="afdfa01d9f277051e44d7ed9663555b52"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdfa01d9f277051e44d7ed9663555b52">&#9670;&nbsp;</a></span>dot()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::dot </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>computes the dot product of two vectors </p>
<p><code>sum += x[i] * y[i]</code></p>
<p>This method calls native <code>cublas&lt;t&gt;dot</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements to perform the dot product </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector <code>x</code> </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">y</td><td>pointer to the memory address of the vector <code>y</code> </td></tr>
    <tr><td class="paramname">incy</td><td>stride between consecutive elements of <code>y</code> </td></tr>
    <tr><td class="paramname">result</td><td>the resulting dot product</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a30b437e511b5719f6253d3a9cf0a992c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30b437e511b5719f6253d3a9cf0a992c">&#9670;&nbsp;</a></span>geam()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::geam </td>
          <td>(</td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>ta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>tb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>performs matrix-matrix addition and transposition </p>
<p>This function performs the matrix-matrix addition/transposition:</p>
<p><code>C = alpha * op(A) + beta * op(B)</code>,</p>
<p>where <code>alpha</code> and <code>beta</code> are scalars, and <code>A</code>, <code>B</code> and <code>C</code> are matrices stored in column-major format with dimensions <code>op(A)</code> as <code>m</code> by <code>n</code>, <code>op(B)</code> as <code>m</code> by <code>n</code> and <code>C</code> as <code>m</code> by <code>n</code>, respectively.</p>
<p>The operation is out-of-place if <code>C</code> does not overlap <code>A</code> or <code>B</code>.</p>
<p>The in-place mode supports the following two operations:</p>
<ol type="1">
<li><code>C = alpha * C + beta * op(B)</code></li>
<li><code>C = alpha op(A) + beta * C</code></li>
</ol>
<p>The operation includes the following special cases:</p>
<ol type="1">
<li>the user can reset matrix <code>C</code> to zero by setting <code>alpha</code> and <code>beta</code> to 0</li>
<li>the user can transpose matrix <code>A</code> by setting <code>alpha</code> to 1 and <code>beta</code> to 0</li>
</ol>
<p>The input matrices are in column-major storage.</p>
<p>This method calls native <code>cublas&lt;t&gt;geam</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ta</td><td>transport operation <code>op(A)</code> </td></tr>
    <tr><td class="paramname">tb</td><td>transport operation <code>op(B)</code> </td></tr>
    <tr><td class="paramname">m</td><td>number of rows of matrix <code>C</code> and <code>op(A)</code> </td></tr>
    <tr><td class="paramname">n</td><td>number of columns of matrix <code>C</code> and <code>op(B)</code> </td></tr>
    <tr><td class="paramname">alpha</td><td>pointer to the <code>alpha</code> scalar </td></tr>
    <tr><td class="paramname">A</td><td>pointer to the address of <code>A</code> </td></tr>
    <tr><td class="paramname">lda</td><td>leading dimension of 2D array used to store the matrix <code>A</code> </td></tr>
    <tr><td class="paramname">beta</td><td>pointer to the <code>beta</code> scalar </td></tr>
    <tr><td class="paramname">B</td><td>pointer to the address of <code>B</code> </td></tr>
    <tr><td class="paramname">ldb</td><td>leading dimension of 2D array used to store the matrix <code>B</code> </td></tr>
    <tr><td class="paramname">C</td><td>pointer to the address of <code>C</code> </td></tr>
    <tr><td class="paramname">ldc</td><td>leading dimension of 2D array used to store the matrix <code>C</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a8adbe06476f146b27bb00ba6054e5879"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8adbe06476f146b27bb00ba6054e5879">&#9670;&nbsp;</a></span>gemm()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::gemm </td>
          <td>(</td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>ta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>tb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>performs matrix-matrix multiplication </p>
<p>This function performs matrix-matrix multiplication:</p>
<p><code>C = alpha * op (A) * op (B) + beta * C</code>,</p>
<p>where <code>alpha</code> and <code>beta</code> are scalars, and <code>A</code>, <code>B</code>, and <code>C</code> are 2D matrices stored in column-major format with dimension <code>op(A)</code> as <code>m</code> by <code>k</code>, dimension <code>op(B)</code> as <code>k</code> by <code>n</code>, and <code>C</code> as <code>m</code> by <code>n</code>.</p>
<p>The input matrices are in column-major storage.</p>
<p>This method calls native <code>cublas&lt;t&gt;gemm</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ta</td><td>transport operation <code>op(A)</code> </td></tr>
    <tr><td class="paramname">tb</td><td>transport operation <code>op(B)</code> </td></tr>
    <tr><td class="paramname">m</td><td>number of rows of matrix <code>C</code> and <code>op(A)</code> </td></tr>
    <tr><td class="paramname">n</td><td>number of columns of matrix <code>C</code> and <code>op(B)</code> </td></tr>
    <tr><td class="paramname">k</td><td>number of columns of <code>op(A)</code> and rows of <code>op(B)</code> </td></tr>
    <tr><td class="paramname">alpha</td><td>pointer to the <code>alpha</code> scalar </td></tr>
    <tr><td class="paramname">A</td><td>pointer to the address of <code>A</code> </td></tr>
    <tr><td class="paramname">lda</td><td>leading dimension of 2D array used to store the matrix <code>A</code> </td></tr>
    <tr><td class="paramname">B</td><td>pointer to the address of <code>B</code> </td></tr>
    <tr><td class="paramname">ldb</td><td>leading dimension of 2D array used to store the matrix <code>B</code> </td></tr>
    <tr><td class="paramname">beta</td><td>pointer to the <code>beta</code> scalar </td></tr>
    <tr><td class="paramname">C</td><td>pointer to the address of <code>C</code> </td></tr>
    <tr><td class="paramname">ldc</td><td>leading dimension of 2D array used to store the matrix <code>C</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a56af0e8ed80e5626fe2f594608afa405"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56af0e8ed80e5626fe2f594608afa405">&#9670;&nbsp;</a></span>gemm_batched()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::gemm_batched </td>
          <td>(</td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>ta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>tb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>A</em>[], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>B</em>[], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>C</em>[], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>bc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>performs matrix-matrix multiplication over a batch of matrices </p>
<p>The batch must be <em>uniform</em>. All instances in the batch must have the same dimensions <code>(m, n, k)</code>, leading dimensions <code>(lda, ldb, ldc)</code> and transpositions <code>(ta, tb)</code> for their respective <code>A</code>, <code>B</code> and <code>C</code> matrices. The address of the input matrices and the output matrix of each instance of the batch are read from arrays of pointers passed to the function by the caller.</p>
<p><code>C[i]= alpha * op (A[i]) * op (B[i]) + beta * C[i], i in [0, bc)</code>,</p>
<p>where <code>alpha</code> and <code>beta</code> are scalars, and <code>A</code>[i], <code>B</code>[i], and <code>C</code>[i] are 2D matrices stored in column-major format with dimension <code>op(A)</code> as <code>m</code> by <code>k</code>, dimension <code>op(B)</code> as <code>k</code> by <code>n</code>, and <code>C</code> as <code>m</code> by <code>n</code>.</p>
<p>The input matrices are in column-major storage.</p>
<p>This method calls native <code>cublas&lt;t&gt;gemmBatched</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ta</td><td>transport operation <code>op(A[i])</code> </td></tr>
    <tr><td class="paramname">tb</td><td>transport operation <code>op(B[i])</code> </td></tr>
    <tr><td class="paramname">m</td><td>number of rows of matrix <code>C</code>[i] and <code>op(A[i])</code> </td></tr>
    <tr><td class="paramname">n</td><td>number of columns of matrix <code>C</code>[i] and <code>op(B[i])</code> </td></tr>
    <tr><td class="paramname">k</td><td>number of columns of <code>op(A[i])</code> and rows of <code>op(B[i])</code> </td></tr>
    <tr><td class="paramname">alpha</td><td>pointer to the <code>alpha</code> scalar </td></tr>
    <tr><td class="paramname">A</td><td>array pointer to <code>A</code> batch </td></tr>
    <tr><td class="paramname">lda</td><td>leading dimension of 2D array used to store the matrix <code>A</code>[i] </td></tr>
    <tr><td class="paramname">B</td><td>array pointer to <code>B</code> batch </td></tr>
    <tr><td class="paramname">ldb</td><td>leading dimension of 2D array used to store the matrix <code>B</code>[i] </td></tr>
    <tr><td class="paramname">beta</td><td>pointer to the <code>beta</code> scalar </td></tr>
    <tr><td class="paramname">C</td><td>array pointer to <code>C</code> batch </td></tr>
    <tr><td class="paramname">ldc</td><td>leading dimension of 2D array used to store the matrix <code>C</code>[i] </td></tr>
    <tr><td class="paramname">bc</td><td>batch size (number of matrices)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a36ecdcea0f24575187e44374e583df2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a36ecdcea0f24575187e44374e583df2e">&#9670;&nbsp;</a></span>gemm_sbatched()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::gemm_sbatched </td>
          <td>(</td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>ta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>tb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">long long int&#160;</td>
          <td class="paramname"><em>sA</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">long long int&#160;</td>
          <td class="paramname"><em>sB</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">long long int&#160;</td>
          <td class="paramname"><em>sC</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>bc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>performs matrix-matrix multiplication over a batch of matrices with strided memory access </p>
<p>Here, we use <code>A</code>[i], <code>B</code>[i], <code>C</code>[i] as notation for A, B and C matrices in the <code>i-th</code> instance of the batch, implicitly assuming they are respectively address offsets <code>sA</code>, <code>sB</code>, <code>sC</code> away from <code>A</code>[i-1], <code>B</code>[i-1], <code>C</code>[i-1].</p>
<p>The input matrices are in column-major storage.</p>
<p>This method calls native <code>cublas&lt;t&gt;gemmStridedBatched</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ta</td><td>transport operation <code>op(A[i])</code> </td></tr>
    <tr><td class="paramname">tb</td><td>transport operation <code>op(B[i])</code> </td></tr>
    <tr><td class="paramname">m</td><td>number of rows of matrix <code>C</code>[i] and <code>op(A[i])</code> </td></tr>
    <tr><td class="paramname">n</td><td>number of columns of matrix <code>C</code>[i] and <code>op(B[i])</code> </td></tr>
    <tr><td class="paramname">k</td><td>number of columns of <code>op(A[i])</code> and rows of <code>op(B[i])</code> </td></tr>
    <tr><td class="paramname">alpha</td><td>pointer to the <code>alpha</code> scalar </td></tr>
    <tr><td class="paramname">A</td><td>pointer to <code>A</code> batch </td></tr>
    <tr><td class="paramname">lda</td><td>leading dimension of 2D array used to store the matrix <code>A</code>[i] </td></tr>
    <tr><td class="paramname">sA</td><td>address offset between <code>A</code>[i] and <code>A</code>[i+1] </td></tr>
    <tr><td class="paramname">B</td><td>pointer to <code>B</code> batch </td></tr>
    <tr><td class="paramname">ldb</td><td>leading dimension of 2D array used to store the matrix <code>B</code>[i] </td></tr>
    <tr><td class="paramname">sB</td><td>address offset between <code>B</code>[i] and <code>B</code>[i+1] </td></tr>
    <tr><td class="paramname">beta</td><td>pointer to the <code>beta</code> scalar </td></tr>
    <tr><td class="paramname">C</td><td>pointer to <code>C</code> batch </td></tr>
    <tr><td class="paramname">ldc</td><td>leading dimension of 2D array used to store the matrix <code>C</code>[i] </td></tr>
    <tr><td class="paramname">sC</td><td>address offset between <code>C</code>[i] and <code>C</code>[i+1] </td></tr>
    <tr><td class="paramname">bc</td><td>batch size (number of matrices)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle</dd></dl>
<p>The batch must be <em>uniform</em>. All instances in the batch must have the same dimensions <code>(m, n, k)</code>, leading dimensions <code>(lda, ldb, ldc)</code> and transpositions <code>(ta, tb)</code> for their respective <code>A</code>, <code>B</code> and <code>C</code> matrices. Input matrices <code>A</code>, <code>B</code> and output matrix <code>C</code> for each instance of the batch are located at fixed address offsets from their locations in the previous instance. Pointers to <code>A</code>, <code>B</code> and <code>C</code> matrices for the first instance are passed to the function by the user along with the address <em>offsets</em> - <code>sA</code>, <code>sB</code> and <code>sC</code> that determine the locations of input and output matrices in future instances.</p>
<p><code>C + i*sC = alpha * op (A + i*sA) * op (B + i*sB) + beta * (C + i*sC), i in [0, bc)</code>,</p>
<p>where <code>alpha</code> and <code>beta</code> are scalars, and <code>A</code>[i], <code>B</code>[i], and <code>C</code>[i] are 2D matrices stored in column-major format with dimension <code>op(A)</code> as <code>m</code> by <code>k</code>, dimension <code>op(B)</code> as <code>k</code> by <code>n</code>, and <code>C</code> as <code>m</code> by <code>n</code>.</p>
<p>On certain problem sizes, it might be advantageous to create multiple gemm tasks to take advantage of concurrent kernels, rather than this method. </p>

</div>
</div>
<a id="a72185bf94321948b5b3657cc9c52ad0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72185bf94321948b5b3657cc9c52ad0a">&#9670;&nbsp;</a></span>gemv()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::gemv </td>
          <td>(</td>
          <td class="paramtype">cublasOperation_t&#160;</td>
          <td class="paramname"><em>trans</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>performs matrix-vector multiplication </p>
<p>This function performs matrix-vector multiplication:</p>
<p><code>y = alpha * op (A) * x + beta * y</code>,</p>
<p>where <code>alpha</code> and <code>beta</code> are scalars, <code>A</code> is 2D matrices stored in column-major format with dimension <code>op(A)</code> as <code>m</code> by <code>n</code>, and <code>x</code>, <code>y</code> are vectors with dimension <code>x</code> as <code>n</code>, and <code>y</code> as <code>m</code>.</p>
<p>The input matrices are in column-major storage.</p>
<p>This method calls native <code>cublas&lt;t&gt;gemv</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">trans</td><td>transport operation <code>op(A)</code> </td></tr>
    <tr><td class="paramname">m</td><td>number of rows of matrix <code>op(A)</code> </td></tr>
    <tr><td class="paramname">n</td><td>number of columns of matrix <code>op(A)</code> </td></tr>
    <tr><td class="paramname">alpha</td><td>pointer to the <code>alpha</code> scalar </td></tr>
    <tr><td class="paramname">A</td><td>pointer to the address of <code>A</code> </td></tr>
    <tr><td class="paramname">lda</td><td>leading dimension of 2D array used to store the matrix <code>A</code> </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the address of <code>x</code> </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">beta</td><td>pointer to the <code>beta</code> scalar </td></tr>
    <tr><td class="paramname">y</td><td>pointer to the address of <code>y</code> </td></tr>
    <tr><td class="paramname">incy</td><td>stride between consecutive elements of <code>y</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a2701b05226ef193e45482c1bb56f93de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2701b05226ef193e45482c1bb56f93de">&#9670;&nbsp;</a></span>native_handle()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">cublasHandle_t tf::cublasFlowCapturer::native_handle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>gets the native cublas handle associated with this cublasFlowCapturer </p>
<dl class="section return"><dt>Returns</dt><dd>a native cublas handle of type cublasHandle_t </dd></dl>

</div>
</div>
<a id="a8000fc6dbbb6f6f5a033f1b365e80d38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8000fc6dbbb6f6f5a033f1b365e80d38">&#9670;&nbsp;</a></span>nrm2()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::nrm2 </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>computes the Euclidean norm of a vector </p>
<p>This method calls native <code>cublas&lt;t&gt;nrm2</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements in vector <code>x</code> </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">result</td><td>the result</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="adb8f5d3137f5ccb3469a5bdde454a8bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb8f5d3137f5ccb3469a5bdde454a8bf">&#9670;&nbsp;</a></span>scal()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::scal </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>scalar</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>scales a vector by a scalar </p>
<p>This method calls native <code>cublas&lt;t&gt;scal</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements in vector <code>x</code> </td></tr>
    <tr><td class="paramname">scalar</td><td>scalar used for multiplication </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a32451b05fd7eb937ce8e807b5d5abe1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32451b05fd7eb937ce8e807b5d5abe1f">&#9670;&nbsp;</a></span>swap()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::swap </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>swaps elements between two vectors </p>
<p>This function interchanges the elements of vectors <code>x</code> and <code>y</code>. Hence, the performed operation is:</p>
<p><code>y[j] &lt;-&gt; x[k]</code>,</p>
<p>where <code>j</code> is the index of element in <code>y</code> with a step size <code>incy</code> and <code>k</code> is the index of element in <code>x</code> with a step size <code>incx</code>.</p>
<p>This method calls native <code>cublas&lt;t&gt;swap</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements to perform the dot product </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector <code>x</code> </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">y</td><td>pointer to the memory address of the vector <code>y</code> </td></tr>
    <tr><td class="paramname">incy</td><td>stride between consecutive elements of <code>y</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="af315b411bcaa2bd2bc1436f7f2ca5e21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af315b411bcaa2bd2bc1436f7f2ca5e21">&#9670;&nbsp;</a></span>vcopy()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::vcopy </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>copies a vector to another vector </p>
<p>This function copies <code>n</code> elements from a vector <code>x</code> of a step size <code>incx</code> to another vector <code>y</code> of step size <code>incy</code>.</p>
<p>adds it to the vector <code>y</code> overwriting the latest vector with the result. Hence, the performed operation is:</p>
<p><code>y[j] = x[k]</code>,</p>
<p>where <code>j</code> and <code>k</code> are indices of <code>n</code> elements with step sizes <code>incy</code> and <code>incx</code>.</p>
<p>This method calls native <code>cublas&lt;t&gt;copy</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements to copy </td></tr>
    <tr><td class="paramname">x</td><td>pointer to the memory address of the vector <code>x</code> </td></tr>
    <tr><td class="paramname">incx</td><td>stride between consecutive elements of <code>x</code> </td></tr>
    <tr><td class="paramname">y</td><td>pointer to the memory address of the vector <code>y</code> </td></tr>
    <tr><td class="paramname">incy</td><td>stride between consecutive elements of <code>y</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="af8f5052cbe1203d6ee3d3d40dffbb8eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af8f5052cbe1203d6ee3d3d40dffbb8eb">&#9670;&nbsp;</a></span>vget()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , std::enable_if_t&lt;!std::is_same_v&lt; T, void &gt;, void &gt; *  = nullptr&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::vget </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>d</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incd</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>inch</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>copies vector data from device to host </p>
<p>This method copies <code>n</code> elements from a vector <code>d</code> in GPU memory space to a vector <code>h</code> in host memory space. The storage spacing between consecutive elements is given by <code>inch</code> for the target vector <code>h</code> and by <code>incd</code> for the source vector <code>d</code>.</p>
<p>This method calls native <code>cublasGetVectorAsync</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements </td></tr>
    <tr><td class="paramname">h</td><td>target host pointer </td></tr>
    <tr><td class="paramname">inch</td><td>spacing between consecutive elements in <code>h</code> </td></tr>
    <tr><td class="paramname">d</td><td>source device pointer </td></tr>
    <tr><td class="paramname">incd</td><td>spacing between consecutive elements in <code>d</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<a id="a5e5d2a2502fcfe0094d5ac354995cb71"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e5d2a2502fcfe0094d5ac354995cb71">&#9670;&nbsp;</a></span>vset()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , std::enable_if_t&lt;!std::is_same_v&lt; T, void &gt;, void &gt; *  = nullptr&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classtf_1_1cudaTask.html">cudaTask</a> tf::cublasFlowCapturer::vset </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>inch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>d</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>incd</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>copies vector data from host to device </p>
<p>This method copies <code>n</code> elements from a vector <code>h</code> in host memory space to a vector <code>d</code> in GPU memory space. The storage spacing between consecutive elements is given by <code>inch</code> for the source vector <code>h</code> and by <code>incd</code> for the destination vector <code>d</code>.</p>
<p>This method calls native <code>cublasSetVectorAsync</code> with packed parameters, <code>(handle, args...)</code>, where <code>handle</code> is manaed by the cublasFlowCapturer and <code>args</code>... are the given arguments.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>number of elements </td></tr>
    <tr><td class="paramname">d</td><td>target device pointer </td></tr>
    <tr><td class="paramname">incd</td><td>spacing between consecutive elements in <code>d</code> </td></tr>
    <tr><td class="paramname">h</td><td>source host pointer </td></tr>
    <tr><td class="paramname">inch</td><td>spacing between consecutive elements in <code>h</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classtf_1_1cudaTask.html" title="handle to a node of the internal CUDA graph ">tf::cudaTask</a> handle </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="cublas__flow_8hpp_source.html">cublas_flow.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>tf</b></li><li class="navelem"><a class="el" href="classtf_1_1cublasFlowCapturer.html">cublasFlowCapturer</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
