<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Taskflow Handbook</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname"><a href="https://taskflow.github.io/">Taskflow</a>
   &#160;<span id="projectnumber">3.0.0-Master-Branch</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('cuda__flow_8hpp_source.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">cuda_flow.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="cuda__flow_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#pragma once</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="cuda__task_8hpp.html">cuda_task.hpp</a>&quot;</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="cuda__capturer_8hpp.html">cuda_capturer.hpp</a>&quot;</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &quot;cuda_algorithm/cuda_for_each.hpp&quot;</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &quot;cuda_algorithm/cuda_transform.hpp&quot;</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacetf.html">tf</a> {</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">// class definition: cudaFlow</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html">   29</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtf_1_1cudaFlow.html">cudaFlow</a> {</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;  <span class="keyword">friend</span> <span class="keyword">class </span><a class="code" href="classtf_1_1Executor.html">Executor</a>;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">empty</a>() <span class="keyword">const</span>;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classtf_1_1cudaFlow.html#ac29d95787db4b622e1458bb64da11264">joinable</a>() <span class="keyword">const</span>;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    </div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">noop</a>();</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    </div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a060e1c96111c2134ce0f896420a42cd0">host</a>(C&amp;&amp; callable);</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    </div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">kernel</a>(dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args);</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    </div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">kernel_on</a>(<span class="keywordtype">int</span> d, dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args);</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">memset</a>(<span class="keywordtype">void</span>* dst, <span class="keywordtype">int</span> v, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    </div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">memcpy</a>(<span class="keywordtype">void</span>* tgt, <span class="keyword">const</span> <span class="keywordtype">void</span>* src, <span class="keywordtype">size_t</span> bytes);</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    std::enable_if_t&lt;</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;      is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;      <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    &gt; </div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    <a class="code" href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">zero</a>(T* dst, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    std::enable_if_t&lt;</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;      is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;      <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;    &gt;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    <a class="code" href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">fill</a>(T* dst, T value, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;    </div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, </div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;      std::enable_if_t&lt;!std::is_same_v&lt;T, void&gt;, <span class="keywordtype">void</span>&gt;* = <span class="keyword">nullptr</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    &gt;</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(T* tgt, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> num);</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    </div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> P&gt;</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a99358da15e3bdfa1faabb3e326130e1f">offload_until</a>(P&amp;&amp; predicate);</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;    </div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#ac2269fd7dc8ca04a294a718204703dad">offload_n</a>(<span class="keywordtype">size_t</span> N);</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> P&gt;</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#aea77b710bf74fb3ccc6043592d4cdbc7">join_until</a>(P&amp;&amp; predicate);</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a9b28ad99e4d3c0208422a2db094df277">join_n</a>(<span class="keywordtype">size_t</span> N);</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#afa479a33e555179c400ba2376b7c5f29">join</a>();</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;    <span class="comment">// update methods</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;  </div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;    <span class="comment">// TODO update_kernel_on</span></div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#aa841b36aca935162489b5e7430dafe99">update_kernel</a>(<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, dim3 g, dim3 b, <span class="keywordtype">size_t</span> shm, ArgsT&amp;&amp;... args);</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;    <span class="keyword">template</span> &lt;</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;      <span class="keyword">typename</span> T, </div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;      std::enable_if_t&lt;!std::is_same_v&lt;T, void&gt;, <span class="keywordtype">void</span>&gt;* = <span class="keyword">nullptr</span></div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;    &gt;</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a0644814008b31c7a9bcc64dada5d0ca9">update_copy</a>(<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, T* tgt, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> num);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a8703eba0d22464208b2581d99306d709">update_memcpy</a>(<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, <span class="keywordtype">void</span>* tgt, <span class="keyword">const</span> <span class="keywordtype">void</span>* src, <span class="keywordtype">size_t</span> bytes);</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#ab40c77439e98d51070e32762d2323de1">update_memset</a>(<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, <span class="keywordtype">void</span>* dst, <span class="keywordtype">int</span> ch, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    <span class="comment">// generic algorithms</span></div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;    </div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a53927cca2d935fa7ab2b33e3d6b13dab">single_task</a>(C&amp;&amp; callable);</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    </div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">for_each</a>(I first, I last, C&amp;&amp; callable);</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">for_each_index</a>(I first, I last, I step, C&amp;&amp; callable);</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;  </div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C, <span class="keyword">typename</span>... S&gt;</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a552f2da29009113beee4ee90bc95ae65">transform</a>(I first, I last, C&amp;&amp; callable, S... srcs);</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;    </div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;    <span class="comment">// TODO: </span></div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;    <span class="comment">//template &lt;typename T, typename B&gt;</span></div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;    <span class="comment">//cudaTask reduce(T* tgt, size_t N, T&amp; init, B&amp;&amp; op);</span></div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;    <span class="comment">//</span></div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;    </div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    <span class="comment">// subflow</span></div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;    </div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a89c389fff64a16e5dd8c60875d3b514d">capture</a>(C&amp;&amp; callable);</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;    </div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;    <span class="comment">//cudaFlow(int, Executor&amp;, cudaGraph&amp;);</span></div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;    <a class="code" href="classtf_1_1cudaFlow.html">cudaFlow</a>(<a class="code" href="classtf_1_1Executor.html">Executor</a>&amp; executor, cudaGraph&amp;);</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;    ~<a class="code" href="classtf_1_1cudaFlow.html">cudaFlow</a>();</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    </div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;    <a class="code" href="classtf_1_1Executor.html">Executor</a>&amp; _executor;</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;    cudaGraph&amp; _graph;</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;    </div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;    <span class="keywordtype">bool</span> _joinable {<span class="keyword">true</span>};</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;    </div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;    cudaGraphExec_t _executable {<span class="keyword">nullptr</span>};</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;    <span class="keywordtype">void</span> _create_executable();</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;    <span class="keywordtype">void</span> _destroy_executable();</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;};</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;<span class="comment">// Constructor</span></div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;<span class="keyword">inline</span> cudaFlow::cudaFlow(<a class="code" href="classtf_1_1Executor.html">Executor</a>&amp; e, cudaGraph&amp; g) :</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;  _executor{e}, _graph {g} {</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;}</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;<span class="comment">// Destructor</span></div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;<span class="keyword">inline</span> cudaFlow::~cudaFlow() {</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;  assert(_executable == <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;}</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment">// Procedure: _create_executable</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="keyword">inline</span> <span class="keywordtype">void</span> cudaFlow::_create_executable() {</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;  assert(_executable == <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;    cudaGraphInstantiate(</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;      &amp;_executable, _graph._native_handle, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, 0</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;    ),</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;    <span class="stringliteral">&quot;failed to create an executable graph&quot;</span></div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;  );</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;}</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;<span class="comment">// Procedure: _destroy_executable</span></div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;<span class="keyword">inline</span> <span class="keywordtype">void</span> cudaFlow::_destroy_executable() {</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;  assert(_executable != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;    cudaGraphExecDestroy(_executable), <span class="stringliteral">&quot;failed to destroy executable graph&quot;</span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;  );</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  _executable = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;}</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="comment">// Function: empty</span></div><div class="line"><a name="l00443"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">  443</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">cudaFlow::empty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;  <span class="keywordflow">return</span> _graph._nodes.empty();</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;}</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;<span class="comment">// Function: joinable</span></div><div class="line"><a name="l00448"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ac29d95787db4b622e1458bb64da11264">  448</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classtf_1_1cudaFlow.html#ac29d95787db4b622e1458bb64da11264">cudaFlow::joinable</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;  <span class="keywordflow">return</span> _joinable;</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;} </div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="comment">// Function: noop</span></div><div class="line"><a name="l00453"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">  453</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">cudaFlow::noop</a>() {</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back( </div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Empty&gt;{}</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;  );</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;    cudaGraphAddEmptyNode(</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;    ),</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;    <span class="stringliteral">&quot;failed to create a no-operation (empty) node&quot;</span></div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;  );</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;}</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;<span class="comment">// Function: host</span></div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00471"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a060e1c96111c2134ce0f896420a42cd0">  471</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a060e1c96111c2134ce0f896420a42cd0">cudaFlow::host</a>(C&amp;&amp; c) {</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;  </div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Host&gt;{}, std::forward&lt;C&gt;(c)</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;  );</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;  <span class="keyword">auto</span>&amp; h = std::get&lt;cudaNode::Host&gt;(node-&gt;_handle);</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;  cudaHostNodeParams p;</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;  p.fn = cudaNode::Host::callback;</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;  p.userData = &amp;h;</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;    ::cudaGraphAddHostNode(&amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;    <span class="stringliteral">&quot;failed to create a host node&quot;</span></div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;  );</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;  </div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;}</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;<span class="comment">// Function: kernel</span></div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00493"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">  493</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">cudaFlow::kernel</a>(</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;  dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;) {</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;  </div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;  <span class="keyword">using</span> traits = function_traits&lt;F&gt;;</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;  static_assert(traits::arity == <span class="keyword">sizeof</span>...(ArgsT), <span class="stringliteral">&quot;arity mismatches&quot;</span>);</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Kernel&gt;{}, (<span class="keywordtype">void</span>*)f</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;  );</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;  </div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;  cudaKernelNodeParams p;</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;  <span class="keywordtype">void</span>* arguments[<span class="keyword">sizeof</span>...(ArgsT)] = { (<span class="keywordtype">void</span>*)(&amp;args)... };</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;  p.func = (<span class="keywordtype">void</span>*)f;</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;  p.gridDim = g;</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;  p.blockDim = b;</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;  p.sharedMemBytes = s;</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;  p.kernelParams = arguments;</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;  p.extra = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    cudaGraphAddKernelNode(</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;    ),</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda kernel task&quot;</span></div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;  );</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;}</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;<span class="comment">// Function: kernel</span></div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00526"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">  526</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">cudaFlow::kernel_on</a>(</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;  <span class="keywordtype">int</span> d, dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;) {</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;  </div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;  <span class="keyword">using</span> traits = function_traits&lt;F&gt;;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;  static_assert(traits::arity == <span class="keyword">sizeof</span>...(ArgsT), <span class="stringliteral">&quot;arity mismatches&quot;</span>);</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;  </div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Kernel&gt;{}, (<span class="keywordtype">void</span>*)f</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;  );</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;  </div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;  cudaKernelNodeParams p;</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;  <span class="keywordtype">void</span>* arguments[<span class="keyword">sizeof</span>...(ArgsT)] = { (<span class="keywordtype">void</span>*)(&amp;args)... };</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;  p.func = (<span class="keywordtype">void</span>*)f;</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;  p.gridDim = g;</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;  p.blockDim = b;</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;  p.sharedMemBytes = s;</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;  p.kernelParams = arguments;</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;  p.extra = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;  <a class="code" href="classtf_1_1cudaScopedDevice.html">cudaScopedDevice</a> ctx(d);</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;    ::cudaGraphAddKernelNode(</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;    ),</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda kernel task on device &quot;</span>, d</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;  );</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;}</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;<span class="comment">// Function: zero</span></div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;std::enable_if_t&lt;</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;  is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;  <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;&gt; </div><div class="line"><a name="l00564"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">  564</a></span>&#160;<a class="code" href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">cudaFlow::zero</a>(T* dst, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Memset&gt;{}</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;  );</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;  </div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;  cudaMemsetParams p;</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;  p.dst = dst;</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;  p.value = 0;</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;  p.pitch = 0;</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;  p.elementSize = <span class="keyword">sizeof</span>(T);  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;  p.width = count;</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;  p.height = 1;</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;</div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;    cudaGraphAddMemsetNode(</div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;    ),</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda memset (zero) task&quot;</span></div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;  );</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;}</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;    </div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;<span class="comment">// Function: fill</span></div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;std::enable_if_t&lt;</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;  is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;  <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;&gt;</div><div class="line"><a name="l00594"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">  594</a></span>&#160;<a class="code" href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">cudaFlow::fill</a>(T* dst, T value, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Memset&gt;{}</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;  );</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;  </div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;  cudaMemsetParams p;</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;  p.dst = dst;</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;  <span class="comment">// perform bit-wise copy</span></div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;  p.value = 0;  <span class="comment">// crucial</span></div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;  static_assert(<span class="keyword">sizeof</span>(T) &lt;= <span class="keyword">sizeof</span>(p.value), <span class="stringliteral">&quot;internal error&quot;</span>);</div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;  std::memcpy(&amp;p.value, &amp;value, <span class="keyword">sizeof</span>(T));</div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;  p.pitch = 0;</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;  p.elementSize = <span class="keyword">sizeof</span>(T);  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;  p.width = count;</div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;  p.height = 1;</div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;    cudaGraphAddMemsetNode(</div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;    ),</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda memset (fill) task&quot;</span></div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;  );</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;</div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;}</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;<span class="comment">// Function: copy</span></div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;<span class="keyword">template</span> &lt;</div><div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;  <span class="keyword">typename</span> T,</div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;  std::enable_if_t&lt;!std::is_same_v&lt;T, void&gt;, <span class="keywordtype">void</span>&gt;*</div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;&gt;</div><div class="line"><a name="l00627"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">  627</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">cudaFlow::copy</a>(T* tgt, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> num) {</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;  <span class="keyword">using</span> U = std::decay_t&lt;T&gt;;</div><div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;</div><div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Memcpy&gt;{}</div><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;  );</div><div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;  </div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;  cudaMemcpy3DParms p;</div><div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;  p.srcArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;  p.srcPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;  p.srcPtr = ::make_cudaPitchedPtr(const_cast&lt;T*&gt;(src), num*<span class="keyword">sizeof</span>(U), num, 1);</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;  p.dstArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;  p.dstPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;  p.dstPtr = ::make_cudaPitchedPtr(tgt, num*<span class="keyword">sizeof</span>(U), num, 1);</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;  p.extent = ::make_cudaExtent(num*<span class="keyword">sizeof</span>(U), 1, 1);</div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;  p.kind = cudaMemcpyDefault;</div><div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;    cudaGraphAddMemcpyNode(</div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;    ),</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda memcpy (copy) task&quot;</span></div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;  );</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;}</div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;<span class="comment">// Function: memset</span></div><div class="line"><a name="l00656"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">  656</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">cudaFlow::memset</a>(<span class="keywordtype">void</span>* dst, <span class="keywordtype">int</span> ch, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Memset&gt;{}</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;  );</div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;  </div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;  cudaMemsetParams p;</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;  p.dst = dst;</div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;  p.value = ch;</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;  p.pitch = 0;</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;  <span class="comment">//p.elementSize = (count &amp; 1) == 0 ? ((count &amp; 3) == 0 ? 4 : 2) : 1;</span></div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;  <span class="comment">//p.width = (count &amp; 1) == 0 ? ((count &amp; 3) == 0 ? count &gt;&gt; 2 : count &gt;&gt; 1) : count;</span></div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;  p.elementSize = 1;  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;  p.width = count;</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;  p.height = 1;</div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;    cudaGraphAddMemsetNode(</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;    ),</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda memset task&quot;</span></div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;  );</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;  </div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;}</div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;<span class="comment">// Function: memcpy</span></div><div class="line"><a name="l00682"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">  682</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">cudaFlow::memcpy</a>(<span class="keywordtype">void</span>* tgt, <span class="keyword">const</span> <span class="keywordtype">void</span>* src, <span class="keywordtype">size_t</span> bytes) {</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Memcpy&gt;{}</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;  );</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;  </div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;  <span class="comment">// Parameters in cudaPitchedPtr</span></div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;  <span class="comment">// d   - Pointer to allocated memory</span></div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;  <span class="comment">// p   - Pitch of allocated memory in bytes</span></div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;  <span class="comment">// xsz - Logical width of allocation in elements</span></div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;  <span class="comment">// ysz - Logical height of allocation in elements</span></div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;  cudaMemcpy3DParms p;</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;  p.srcArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;  p.srcPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;  p.srcPtr = ::make_cudaPitchedPtr(const_cast&lt;void*&gt;(src), bytes, bytes, 1);</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;  p.dstArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;  p.dstPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;  p.dstPtr = ::make_cudaPitchedPtr(tgt, bytes, bytes, 1);</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;  p.extent = ::make_cudaExtent(bytes, 1, 1);</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;  p.kind = cudaMemcpyDefault;</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;    cudaGraphAddMemcpyNode(</div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, &amp;p</div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;    ),</div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;    <span class="stringliteral">&quot;failed to create a cuda memcpy task&quot;</span></div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;  );</div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;</div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;}</div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;<span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;<span class="comment">// update methods</span></div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;<span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;<span class="comment">// Function: update kernel parameters</span></div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00718"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#aa841b36aca935162489b5e7430dafe99">  718</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#aa841b36aca935162489b5e7430dafe99">cudaFlow::update_kernel</a>(</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;  <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, ArgsT&amp;&amp;... args</div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;) {</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;</div><div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;  <span class="keywordflow">if</span>(ct.<a class="code" href="classtf_1_1cudaTask.html#a7eab02ec6633a5cf17cc15898db2d648">type</a>() != CUDA_KERNEL_TASK) {</div><div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;    TF_THROW(ct, <span class="stringliteral">&quot; is not a kernel task&quot;</span>);</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;  }</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;  cudaKernelNodeParams p;</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;  </div><div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;  <span class="keywordtype">void</span>* arguments[<span class="keyword">sizeof</span>...(ArgsT)] = { (<span class="keywordtype">void</span>*)(&amp;args)... };</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;  p.func = std::get&lt;cudaNode::Kernel&gt;((ct._node)-&gt;_handle).func;</div><div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;  p.gridDim = g;</div><div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;  p.blockDim = b;</div><div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;  p.sharedMemBytes = s;</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;  p.kernelParams = arguments;</div><div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;  p.extra = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;  </div><div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;  <span class="comment">//TF_CHECK_CUDA(</span></div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;  <span class="comment">//  cudaGraphKernelNodeSetParams(ct._node-&gt;_native_handle, &amp;p),</span></div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;  <span class="comment">//  &quot;failed to update a cudaGraph node of kernel task&quot;</span></div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;  <span class="comment">//);</span></div><div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;    cudaGraphExecKernelNodeSetParams(</div><div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;      _executable, ct._node-&gt;_native_handle, &amp;p</div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;    ),</div><div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;    <span class="stringliteral">&quot;failed to update kernel parameter on &quot;</span>, ct</div><div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;  );</div><div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;} </div><div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;</div><div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;<span class="comment">// Function: update copy parameters</span></div><div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;<span class="keyword">template</span> &lt;</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;  <span class="keyword">typename</span> T,</div><div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;  std::enable_if_t&lt;!std::is_same_v&lt;T, void&gt;, <span class="keywordtype">void</span>&gt;*</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;&gt;</div><div class="line"><a name="l00754"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a0644814008b31c7a9bcc64dada5d0ca9">  754</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a0644814008b31c7a9bcc64dada5d0ca9">cudaFlow::update_copy</a>(<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, T* tgt, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> num) {</div><div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;  </div><div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;  <span class="keywordflow">if</span>(ct.<a class="code" href="classtf_1_1cudaTask.html#a7eab02ec6633a5cf17cc15898db2d648">type</a>() != CUDA_MEMCPY_TASK) {</div><div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;    TF_THROW(ct, <span class="stringliteral">&quot; is not a memcpy task&quot;</span>);</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;  }</div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;</div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;  <span class="keyword">using</span> U = std::decay_t&lt;T&gt;;</div><div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;</div><div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;  cudaMemcpy3DParms p;</div><div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;</div><div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;  p.srcArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;  p.srcPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;  p.srcPtr = ::make_cudaPitchedPtr(const_cast&lt;T*&gt;(src), num*<span class="keyword">sizeof</span>(U), num, 1);</div><div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;  p.dstArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;  p.dstPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;  p.dstPtr = ::make_cudaPitchedPtr(tgt, num*<span class="keyword">sizeof</span>(U), num, 1);</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;  p.extent = ::make_cudaExtent(num*<span class="keyword">sizeof</span>(U), 1, 1);</div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;  p.kind = cudaMemcpyDefault;</div><div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;</div><div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;  <span class="comment">//TF_CHECK_CUDA(</span></div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;  <span class="comment">//  cudaGraphMemcpyNodeSetParams(ct._node-&gt;_native_handle, &amp;p),</span></div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;  <span class="comment">//  &quot;failed to update a cudaGraph node of memcpy task&quot;</span></div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;  <span class="comment">//);</span></div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;</div><div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;    cudaGraphExecMemcpyNodeSetParams(</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;      _executable, ct._node-&gt;_native_handle, &amp;p</div><div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;    ),</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;    <span class="stringliteral">&quot;failed to update memcpy parameter on &quot;</span>, ct</div><div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;  );</div><div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;}</div><div class="line"><a name="l00785"></a><span class="lineno">  785</span>&#160;</div><div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160;<span class="comment">// Function: update memcpy parameters</span></div><div class="line"><a name="l00787"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a8703eba0d22464208b2581d99306d709">  787</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a8703eba0d22464208b2581d99306d709">cudaFlow::update_memcpy</a>(</div><div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160;  <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, <span class="keywordtype">void</span>* tgt, <span class="keyword">const</span> <span class="keywordtype">void</span>* src, <span class="keywordtype">size_t</span> bytes</div><div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;) {</div><div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;  </div><div class="line"><a name="l00791"></a><span class="lineno">  791</span>&#160;  <span class="keywordflow">if</span>(ct.<a class="code" href="classtf_1_1cudaTask.html#a7eab02ec6633a5cf17cc15898db2d648">type</a>() != CUDA_MEMCPY_TASK) {</div><div class="line"><a name="l00792"></a><span class="lineno">  792</span>&#160;    TF_THROW(ct, <span class="stringliteral">&quot; is not a memcpy task&quot;</span>);</div><div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;  }</div><div class="line"><a name="l00794"></a><span class="lineno">  794</span>&#160;</div><div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;  cudaMemcpy3DParms p;</div><div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;</div><div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;  p.srcArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;  p.srcPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;  p.srcPtr = ::make_cudaPitchedPtr(const_cast&lt;void*&gt;(src), bytes, bytes, 1);</div><div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;  p.dstArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;  p.dstPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;  p.dstPtr = ::make_cudaPitchedPtr(tgt, bytes, bytes, 1);</div><div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;  p.extent = ::make_cudaExtent(bytes, 1, 1);</div><div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;  p.kind = cudaMemcpyDefault;</div><div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;</div><div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;  <span class="comment">//TF_CHECK_CUDA(</span></div><div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;  <span class="comment">//  cudaGraphMemcpyNodeSetParams(ct._node-&gt;_native_handle, &amp;p),</span></div><div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;  <span class="comment">//  &quot;failed to update a cudaGraph node of memcpy task&quot;</span></div><div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;  <span class="comment">//);</span></div><div class="line"><a name="l00810"></a><span class="lineno">  810</span>&#160;</div><div class="line"><a name="l00811"></a><span class="lineno">  811</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00812"></a><span class="lineno">  812</span>&#160;    cudaGraphExecMemcpyNodeSetParams(_executable, ct._node-&gt;_native_handle, &amp;p),</div><div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;    <span class="stringliteral">&quot;failed to update memcpy parameter on &quot;</span>, ct</div><div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;  );</div><div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;}</div><div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;</div><div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;<span class="keyword">inline</span></div><div class="line"><a name="l00818"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ab40c77439e98d51070e32762d2323de1">  818</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#ab40c77439e98d51070e32762d2323de1">cudaFlow::update_memset</a>(<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> ct, <span class="keywordtype">void</span>* dst, <span class="keywordtype">int</span> ch, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;</div><div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;  <span class="keywordflow">if</span>(ct.<a class="code" href="classtf_1_1cudaTask.html#a7eab02ec6633a5cf17cc15898db2d648">type</a>() != CUDA_MEMSET_TASK) {</div><div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;    TF_THROW(ct, <span class="stringliteral">&quot; is not a memset task&quot;</span>);</div><div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;  }</div><div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160;</div><div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;  cudaMemsetParams p;</div><div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;  p.dst = dst;</div><div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;  p.value = ch;</div><div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;  p.pitch = 0;</div><div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;  <span class="comment">//p.elementSize = (count &amp; 1) == 0 ? ((count &amp; 3) == 0 ? 4 : 2) : 1;</span></div><div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;  <span class="comment">//p.width = (count &amp; 1) == 0 ? ((count &amp; 3) == 0 ? count &gt;&gt; 2 : count &gt;&gt; 1) : count;</span></div><div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;  p.elementSize = 1;  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160;  p.width = count;</div><div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;  p.height = 1;</div><div class="line"><a name="l00833"></a><span class="lineno">  833</span>&#160;</div><div class="line"><a name="l00834"></a><span class="lineno">  834</span>&#160;  <span class="comment">//TF_CHECK_CUDA(</span></div><div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;  <span class="comment">//  cudaGraphMemsetNodeSetParams(ct._node-&gt;_native_handle, &amp;p),</span></div><div class="line"><a name="l00836"></a><span class="lineno">  836</span>&#160;  <span class="comment">//  &quot;failed to update a cudaGraph node of memset task&quot;</span></div><div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;  <span class="comment">//);</span></div><div class="line"><a name="l00838"></a><span class="lineno">  838</span>&#160;</div><div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00840"></a><span class="lineno">  840</span>&#160;    cudaGraphExecMemsetNodeSetParams(</div><div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160;      _executable, ct._node-&gt;_native_handle, &amp;p</div><div class="line"><a name="l00842"></a><span class="lineno">  842</span>&#160;    ),</div><div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;    <span class="stringliteral">&quot;failed to update memset parameter on &quot;</span>, ct</div><div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;  );</div><div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160;}</div><div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;</div><div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;<span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;<span class="comment">// Generic Algorithm API</span></div><div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160;<span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line"><a name="l00850"></a><span class="lineno">  850</span>&#160;    </div><div class="line"><a name="l00851"></a><span class="lineno">  851</span>&#160;<span class="comment">// Function: single_task</span></div><div class="line"><a name="l00852"></a><span class="lineno">  852</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00853"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a53927cca2d935fa7ab2b33e3d6b13dab">  853</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a53927cca2d935fa7ab2b33e3d6b13dab">cudaFlow::single_task</a>(C&amp;&amp; c) {</div><div class="line"><a name="l00854"></a><span class="lineno">  854</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">kernel</a>(</div><div class="line"><a name="l00855"></a><span class="lineno">  855</span>&#160;    1, 1, 0, cuda_single_task&lt;C&gt;, std::forward&lt;C&gt;(c)</div><div class="line"><a name="l00856"></a><span class="lineno">  856</span>&#160;  );</div><div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160;}</div><div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;</div><div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;<span class="comment">// Function: for_each</span></div><div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00861"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">  861</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">cudaFlow::for_each</a>(I first, I last, C&amp;&amp; c) {</div><div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;  </div><div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;  <span class="keywordtype">size_t</span> N = std::distance(first, last);</div><div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;  <span class="keywordtype">size_t</span> B = cuda_default_threads_per_block(N);</div><div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;  </div><div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;  <span class="comment">// TODO: special case when N is 0?</span></div><div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;</div><div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">kernel</a>(</div><div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;    (N+B-1) / B, B, 0, cuda_for_each&lt;I, C&gt;, first, N, std::forward&lt;C&gt;(c)</div><div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;  );</div><div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;}</div><div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;</div><div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;<span class="comment">// Function: for_each_index</span></div><div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00875"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">  875</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">cudaFlow::for_each_index</a>(I beg, I end, I inc, C&amp;&amp; c) {</div><div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;      </div><div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;  <span class="keywordflow">if</span>(is_range_invalid(beg, end, inc)) {</div><div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160;    TF_THROW(<span class="stringliteral">&quot;invalid range [&quot;</span>, beg, <span class="stringliteral">&quot;, &quot;</span>, end, <span class="stringliteral">&quot;) with inc size &quot;</span>, inc);</div><div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;  }</div><div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;  </div><div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160;  <span class="comment">// TODO: special case when N is 0?</span></div><div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;</div><div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;  <span class="keywordtype">size_t</span> N = distance(beg, end, inc);</div><div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;  <span class="keywordtype">size_t</span> B = cuda_default_threads_per_block(N);</div><div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;</div><div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">kernel</a>(</div><div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;    (N+B-1) / B, B, 0, cuda_for_each_index&lt;I, C&gt;, beg, inc, N, std::forward&lt;C&gt;(c)</div><div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;  );</div><div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;}</div><div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160;</div><div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;<span class="comment">// Function: transform</span></div><div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C, <span class="keyword">typename</span>... S&gt;</div><div class="line"><a name="l00893"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a552f2da29009113beee4ee90bc95ae65">  893</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a552f2da29009113beee4ee90bc95ae65">cudaFlow::transform</a>(I first, I last, C&amp;&amp; c, S... srcs) {</div><div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;  </div><div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;  <span class="comment">// TODO: special case when N is 0?</span></div><div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;  </div><div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;  <span class="keywordtype">size_t</span> N = std::distance(first, last);</div><div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;  <span class="keywordtype">size_t</span> B = cuda_default_threads_per_block(N);</div><div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;</div><div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">kernel</a>(</div><div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160;    (N+B-1) / B, B, 0, cuda_transform&lt;I, C, S...&gt;, </div><div class="line"><a name="l00902"></a><span class="lineno">  902</span>&#160;    first, N, std::forward&lt;C&gt;(c), srcs...</div><div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;  );</div><div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;}</div><div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;</div><div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;<span class="comment">//template &lt;typename T, typename B&gt;&gt;</span></div><div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;<span class="comment">//cudaTask cudaFlow::reduce(T* tgt, size_t N, T&amp; init, B&amp;&amp; op) {</span></div><div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;  <span class="comment">//if(N == 0) {</span></div><div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;    <span class="comment">//return noop();</span></div><div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;  <span class="comment">//}</span></div><div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160;  <span class="comment">//size_t B = cuda_default_threads_per_block(N);</span></div><div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;<span class="comment">//}</span></div><div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;</div><div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;<span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;<span class="comment">// captured flow </span></div><div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;<span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;</div><div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;<span class="comment">// Function: capture</span></div><div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00920"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a89c389fff64a16e5dd8c60875d3b514d">  920</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a89c389fff64a16e5dd8c60875d3b514d">cudaFlow::capture</a>(C&amp;&amp; c) {</div><div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;</div><div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;  <span class="comment">// insert a subflow node</span></div><div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;    _graph, std::in_place_type_t&lt;cudaNode::Subflow&gt;{}</div><div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;  );</div><div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;  </div><div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;  <span class="comment">// construct a captured flow from the callable</span></div><div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160;  <span class="keyword">auto</span>&amp; node_handle = std::get&lt;cudaNode::Subflow&gt;(node-&gt;_handle);</div><div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160;  <a class="code" href="classtf_1_1cudaFlowCapturer.html">cudaFlowCapturer</a> capturer(node_handle.graph);</div><div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;</div><div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;  c(capturer);</div><div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160;  </div><div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;  <span class="comment">// obtain the optimized captured graph</span></div><div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;  <span class="keyword">auto</span> captured = capturer._capture();</div><div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;  <span class="comment">//cuda_dump_graph(std::cout, captured);</span></div><div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;</div><div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160;  TF_CHECK_CUDA(</div><div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;    cudaGraphAddChildGraphNode(</div><div class="line"><a name="l00939"></a><span class="lineno">  939</span>&#160;      &amp;node-&gt;_native_handle, _graph._native_handle, <span class="keyword">nullptr</span>, 0, captured</div><div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160;    ), </div><div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;    <span class="stringliteral">&quot;failed to add a cudaFlow capturer task&quot;</span></div><div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;  );</div><div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160;  </div><div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;  TF_CHECK_CUDA(cudaGraphDestroy(captured), <span class="stringliteral">&quot;failed to destroy captured graph&quot;</span>);</div><div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;</div><div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;}</div><div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160;</div><div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;</div><div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;}  <span class="comment">// end of namespace tf -----------------------------------------------------</span></div><div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160;</div><div class="line"><a name="l00952"></a><span class="lineno">  952</span>&#160;</div><div class="ttc" id="classtf_1_1cudaFlow_html_a97c248490dbde983378f757239eaed4a"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">tf::cudaFlow::for_each</a></div><div class="ttdeci">cudaTask for_each(I first, I last, C &amp;&amp;callable)</div><div class="ttdoc">applies a callable to each dereferenced element of the data array </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:861</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ab40c77439e98d51070e32762d2323de1"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ab40c77439e98d51070e32762d2323de1">tf::cudaFlow::update_memset</a></div><div class="ttdeci">void update_memset(cudaTask ct, void *dst, int ch, size_t count)</div><div class="ttdoc">updates parameters of a memset task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:818</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ad37637606f0643f360e9eda1f9a6e559"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">tf::cudaFlow::memcpy</a></div><div class="ttdeci">cudaTask memcpy(void *tgt, const void *src, size_t bytes)</div><div class="ttdoc">creates a memcpy task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:682</div></div>
<div class="ttc" id="classtf_1_1cudaScopedDevice_html"><div class="ttname"><a href="classtf_1_1cudaScopedDevice.html">tf::cudaScopedDevice</a></div><div class="ttdoc">RAII-styled device context switch. </div><div class="ttdef"><b>Definition:</b> cuda_device.hpp:279</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a060e1c96111c2134ce0f896420a42cd0"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a060e1c96111c2134ce0f896420a42cd0">tf::cudaFlow::host</a></div><div class="ttdeci">cudaTask host(C &amp;&amp;callable)</div><div class="ttdoc">creates a host execution task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:471</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_af03e04771b655f9e629eb4c22e19b19f"><div class="ttname"><a href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">tf::cudaFlow::copy</a></div><div class="ttdeci">cudaTask copy(T *tgt, const T *src, size_t num)</div><div class="ttdoc">creates a copy task of typed data </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:627</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_aee1fa4aff12a41737ea585fa2e106a35"><div class="ttname"><a href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">tf::cudaFlow::fill</a></div><div class="ttdeci">std::enable_if_t&lt; is_pod_v&lt; T &gt; &amp;&amp;(sizeof(T)==1||sizeof(T)==2||sizeof(T)==4), cudaTask &gt; fill(T *dst, T value, size_t count)</div><div class="ttdoc">creates a fill task that fills a typed memory block with a value </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:594</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ab5a7c12e383be4972844a9f29033e487"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">tf::cudaFlow::for_each_index</a></div><div class="ttdeci">cudaTask for_each_index(I first, I last, I step, C &amp;&amp;callable)</div><div class="ttdoc">applies a callable to each index in the range with the step size </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:875</div></div>
<div class="ttc" id="namespacetf_html"><div class="ttname"><a href="namespacetf.html">tf</a></div><div class="ttdef"><b>Definition:</b> flow_builder.hpp:9</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a079ca65da35301e5aafd45878a19e9d2"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">tf::cudaFlow::memset</a></div><div class="ttdeci">cudaTask memset(void *dst, int v, size_t count)</div><div class="ttdoc">creates a memset task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:656</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a8703eba0d22464208b2581d99306d709"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a8703eba0d22464208b2581d99306d709">tf::cudaFlow::update_memcpy</a></div><div class="ttdeci">void update_memcpy(cudaTask ct, void *tgt, const void *src, size_t bytes)</div><div class="ttdoc">updates parameters of a memcpy task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:787</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a1926f45a038d8faa9c1b1ee43fd29a93"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">tf::cudaFlow::empty</a></div><div class="ttdeci">bool empty() const</div><div class="ttdoc">queries the emptiness of the graph </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:443</div></div>
<div class="ttc" id="cuda__task_8hpp_html"><div class="ttname"><a href="cuda__task_8hpp.html">cuda_task.hpp</a></div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html"><div class="ttname"><a href="classtf_1_1cudaFlow.html">tf::cudaFlow</a></div><div class="ttdoc">class for building a CUDA task dependency graph </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:29</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a30b2e107cb2c90a37f467b28d1b42a74"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">tf::cudaFlow::noop</a></div><div class="ttdeci">cudaTask noop()</div><div class="ttdoc">creates a no-operation task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:453</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_adb731be71bdd436dfb5e36e6213a9a17"><div class="ttname"><a href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">tf::cudaFlow::kernel</a></div><div class="ttdeci">cudaTask kernel(dim3 g, dim3 b, size_t s, F &amp;&amp;f, ArgsT &amp;&amp;... args)</div><div class="ttdoc">creates a kernel task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:493</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_aea77b710bf74fb3ccc6043592d4cdbc7"><div class="ttname"><a href="classtf_1_1cudaFlow.html#aea77b710bf74fb3ccc6043592d4cdbc7">tf::cudaFlow::join_until</a></div><div class="ttdeci">void join_until(P &amp;&amp;predicate)</div><div class="ttdoc">offloads the cudaFlow with the given stop predicate and then joins the execution </div><div class="ttdef"><b>Definition:</b> executor.hpp:1439</div></div>
<div class="ttc" id="classtf_1_1cudaTask_html_a7eab02ec6633a5cf17cc15898db2d648"><div class="ttname"><a href="classtf_1_1cudaTask.html#a7eab02ec6633a5cf17cc15898db2d648">tf::cudaTask::type</a></div><div class="ttdeci">cudaTaskType type() const</div><div class="ttdoc">queries the task type </div><div class="ttdef"><b>Definition:</b> cuda_task.hpp:187</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a4a839dbaa01237a440edfebe8faf4e5b"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">tf::cudaFlow::kernel_on</a></div><div class="ttdeci">cudaTask kernel_on(int d, dim3 g, dim3 b, size_t s, F &amp;&amp;f, ArgsT &amp;&amp;... args)</div><div class="ttdoc">creates a kernel task on a device </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:526</div></div>
<div class="ttc" id="cuda__capturer_8hpp_html"><div class="ttname"><a href="cuda__capturer_8hpp.html">cuda_capturer.hpp</a></div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a552f2da29009113beee4ee90bc95ae65"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a552f2da29009113beee4ee90bc95ae65">tf::cudaFlow::transform</a></div><div class="ttdeci">cudaTask transform(I first, I last, C &amp;&amp;callable, S... srcs)</div><div class="ttdoc">applies a callable to a source range and stores the result in a target range </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:893</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_afa479a33e555179c400ba2376b7c5f29"><div class="ttname"><a href="classtf_1_1cudaFlow.html#afa479a33e555179c400ba2376b7c5f29">tf::cudaFlow::join</a></div><div class="ttdeci">void join()</div><div class="ttdoc">offloads the cudaFlow and executes it once, and then joins the execution </div><div class="ttdef"><b>Definition:</b> executor.hpp:1456</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a0644814008b31c7a9bcc64dada5d0ca9"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a0644814008b31c7a9bcc64dada5d0ca9">tf::cudaFlow::update_copy</a></div><div class="ttdeci">void update_copy(cudaTask ct, T *tgt, const T *src, size_t num)</div><div class="ttdoc">updates parameters of a copy task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:754</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ac2269fd7dc8ca04a294a718204703dad"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ac2269fd7dc8ca04a294a718204703dad">tf::cudaFlow::offload_n</a></div><div class="ttdeci">void offload_n(size_t N)</div><div class="ttdoc">offloads the cudaFlow and executes it by the given times </div><div class="ttdef"><b>Definition:</b> executor.hpp:1428</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a53927cca2d935fa7ab2b33e3d6b13dab"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a53927cca2d935fa7ab2b33e3d6b13dab">tf::cudaFlow::single_task</a></div><div class="ttdeci">cudaTask single_task(C &amp;&amp;callable)</div><div class="ttdoc">runs a callable with only a single kernel thread </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:853</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_aa841b36aca935162489b5e7430dafe99"><div class="ttname"><a href="classtf_1_1cudaFlow.html#aa841b36aca935162489b5e7430dafe99">tf::cudaFlow::update_kernel</a></div><div class="ttdeci">void update_kernel(cudaTask ct, dim3 g, dim3 b, size_t shm, ArgsT &amp;&amp;... args)</div><div class="ttdoc">updates parameters of a kernel task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:718</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a89c389fff64a16e5dd8c60875d3b514d"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a89c389fff64a16e5dd8c60875d3b514d">tf::cudaFlow::capture</a></div><div class="ttdeci">cudaTask capture(C &amp;&amp;callable)</div><div class="ttdoc">constructs a subflow graph through capture </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:920</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a99358da15e3bdfa1faabb3e326130e1f"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a99358da15e3bdfa1faabb3e326130e1f">tf::cudaFlow::offload_until</a></div><div class="ttdeci">void offload_until(P &amp;&amp;predicate)</div><div class="ttdoc">offloads the cudaFlow onto a GPU and repeatedly running it until the predicate becomes true ...</div><div class="ttdef"><b>Definition:</b> executor.hpp:1416</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a85789ed8a1f47704cf1f1a2b98969444"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">tf::cudaFlow::offload</a></div><div class="ttdeci">void offload()</div><div class="ttdoc">offloads the cudaFlow and executes it once </div><div class="ttdef"><b>Definition:</b> executor.hpp:1433</div></div>
<div class="ttc" id="classtf_1_1cudaTask_html"><div class="ttname"><a href="classtf_1_1cudaTask.html">tf::cudaTask</a></div><div class="ttdoc">handle to a node in a cudaGraph </div><div class="ttdef"><b>Definition:</b> cuda_task.hpp:53</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ac29d95787db4b622e1458bb64da11264"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ac29d95787db4b622e1458bb64da11264">tf::cudaFlow::joinable</a></div><div class="ttdeci">bool joinable() const</div><div class="ttdoc">queries if the cudaflow is joinable </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:448</div></div>
<div class="ttc" id="classtf_1_1Executor_html"><div class="ttname"><a href="classtf_1_1Executor.html">tf::Executor</a></div><div class="ttdoc">execution interface for running a taskflow graph </div><div class="ttdef"><b>Definition:</b> executor.hpp:28</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a91c1739bb9a2832f306f3d12693a0994"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">tf::cudaFlow::zero</a></div><div class="ttdeci">std::enable_if_t&lt; is_pod_v&lt; T &gt; &amp;&amp;(sizeof(T)==1||sizeof(T)==2||sizeof(T)==4), cudaTask &gt; zero(T *dst, size_t count)</div><div class="ttdoc">creates a zero task that zeroes a typed memory block </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:564</div></div>
<div class="ttc" id="classtf_1_1cudaFlowCapturer_html"><div class="ttname"><a href="classtf_1_1cudaFlowCapturer.html">tf::cudaFlowCapturer</a></div><div class="ttdoc">class object to construct a CUDA graph through stream capture </div><div class="ttdef"><b>Definition:</b> cuda_capturer.hpp:337</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a9b28ad99e4d3c0208422a2db094df277"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a9b28ad99e4d3c0208422a2db094df277">tf::cudaFlow::join_n</a></div><div class="ttdeci">void join_n(size_t N)</div><div class="ttdoc">offloads the cudaFlow and executes it by the given times, and then joins the execution ...</div><div class="ttdef"><b>Definition:</b> executor.hpp:1451</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_88dad41ea55ca2177e141d32a93e931c.html">taskflow</a></li><li class="navelem"><a class="el" href="dir_638d51f8e6f20ea8c720cc8c006296ba.html">cuda</a></li><li class="navelem"><a class="el" href="cuda__flow_8hpp.html">cuda_flow.hpp</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
