<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Taskflow Handbook</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname"><a href="https://taskflow.github.io/">Taskflow</a>
   &#160;<span id="projectnumber">2.7.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('cuda__flow_8hpp_source.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">cuda_flow.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#pragma once</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="preprocessor">#include &quot;cuda_task.hpp&quot;</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &quot;cuda_ops.hpp&quot;</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacetf.html">tf</a> {</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;constexpr <span class="keywordtype">size_t</span> cuda_default_threads_per_block(<span class="keywordtype">size_t</span> N) {</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;  <span class="keywordflow">return</span> N &gt;= 256 ? 256 : 128;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;}</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html">   26</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtf_1_1cudaFlow.html">cudaFlow</a> {</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;  <span class="keyword">friend</span> <span class="keyword">class </span><a class="code" href="classtf_1_1Executor.html">Executor</a>;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">empty</a>() <span class="keyword">const</span>;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;    </div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">noop</a>();</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    </div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;    <span class="comment">// CUDA seems pretty restrictive about calling host in a cudaGraph.</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    <span class="comment">// We disable this function and wait for future stability.</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="comment">//</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    <span class="comment">//@brief creates a host execution task</span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    <span class="comment">//</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    <span class="comment">//@tparam C callable type</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    <span class="comment">//</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    <span class="comment">//@param c a callable object constructible from std::function&lt;void()&gt;.</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    <span class="comment">//A host can only execute CPU-specific functions and cannot do any CUDA calls </span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <span class="comment">//(e.g., cudaMalloc).</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    <span class="comment">//</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;    <span class="comment">//template &lt;typename C&gt;</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    <span class="comment">//cudaTask host(C&amp;&amp; c);</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    </div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">kernel</a>(dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args);</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    </div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">kernel_on</a>(<span class="keywordtype">int</span> d, dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args);</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">memset</a>(<span class="keywordtype">void</span>* dst, <span class="keywordtype">int</span> v, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    </div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">memcpy</a>(<span class="keywordtype">void</span>* tgt, <span class="keyword">const</span> <span class="keywordtype">void</span>* src, <span class="keywordtype">size_t</span> bytes);</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    std::enable_if_t&lt;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;      is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;      <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    &gt; </div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    <a class="code" href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">zero</a>(T* dst, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    std::enable_if_t&lt;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;      is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;      <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    &gt;</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    <a class="code" href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">fill</a>(T* dst, T value, <span class="keywordtype">size_t</span> count);</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    </div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;    <span class="keyword">template</span> &lt;</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;      <span class="keyword">typename</span> T, </div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;      std::enable_if_t&lt;!std::is_same&lt;T, void&gt;::value, <span class="keywordtype">void</span>&gt;* = <span class="keyword">nullptr</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;    &gt;</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(T* tgt, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> num);</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">device</a>(<span class="keywordtype">int</span> <a class="code" href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">device</a>);</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">device</a>() <span class="keyword">const</span>;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> P&gt;</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#aea77b710bf74fb3ccc6043592d4cdbc7">join_until</a>(P&amp;&amp; predicate);</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a9b28ad99e4d3c0208422a2db094df277">join_n</a>(<span class="keywordtype">size_t</span> N);</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#afa479a33e555179c400ba2376b7c5f29">join</a>();</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;    </div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;    <span class="comment">// generic operations</span></div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;    <span class="comment">// ------------------------------------------------------------------------</span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;    </div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">for_each</a>(I first, I last, C&amp;&amp; callable);</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">for_each_index</a>(I first, I last, I step, C&amp;&amp; callable);</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;  </div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> C, <span class="keyword">typename</span>... S&gt;</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a56d0389eeca479ba73419bc011c1a23e">transform</a>(T* tgt, <span class="keywordtype">size_t</span> N, C&amp;&amp; callable, S*... srcs);</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    </div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    <span class="comment">// TODO: </span></div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;    <span class="comment">//template &lt;typename T, typename B&gt;</span></div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;    <span class="comment">//cudaTask reduce(T* tgt, size_t N, T&amp; init, B&amp;&amp; op);</span></div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;    <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> transpose(<span class="keyword">const</span> T* d_in, T* d_out, <span class="keywordtype">size_t</span> rows, <span class="keywordtype">size_t</span> cols);</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;    <span class="comment">//template &lt;typename T&gt;</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;    <span class="comment">//cudaTask inplace_transpose(T* data, size_t rows, size_t cols);</span></div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    <span class="comment">//template &lt;typename T&gt;</span></div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;    <span class="comment">//cudaTask matmul(const T* A, const T* B, T* C, size_t M, size_t K, size_t N);</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;    <span class="comment">//[] (tf::cudaFlow&amp; cf) {</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;    <span class="comment">//  </span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;    <span class="comment">//  auto task1 = cf.for_each(...);</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    <span class="comment">//  auto task2 = cf.matmul(...);</span></div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;    <span class="comment">//  </span></div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;    <span class="comment">//  task1.get&lt;KernelParameter&gt;().block(100);</span></div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    <span class="comment">//  cf.offload();</span></div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;    <span class="comment">//  cf.memset();</span></div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;    <span class="comment">//}</span></div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;    </div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;    <a class="code" href="classtf_1_1cudaFlow.html">cudaFlow</a>(<a class="code" href="classtf_1_1Executor.html">Executor</a>&amp; executor, cudaGraph&amp; graph);</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    </div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;    <a class="code" href="classtf_1_1Executor.html">Executor</a>&amp; _executor;</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    cudaGraph&amp; _graph;</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;    </div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;    <span class="keywordtype">int</span> _device {-1};</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;    <span class="keywordtype">bool</span> _joinable {<span class="keyword">true</span>};</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;    </div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;    <span class="comment">// ---- working items </span></div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> P&gt;</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;    <span class="keywordtype">void</span> offload_until(P&amp;&amp; predicate);</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;    </div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    <span class="keywordtype">void</span> offload_n(<span class="keywordtype">size_t</span> N);</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    <span class="keywordtype">void</span> offload();</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;};</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;<span class="comment">// Constructor</span></div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;<span class="keyword">inline</span> cudaFlow::cudaFlow(<a class="code" href="classtf_1_1Executor.html">Executor</a>&amp; e, cudaGraph&amp; g) : </div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;  _executor  {e},</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;  _graph     {g} {</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;}</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;<span class="comment">// Function: empty</span></div><div class="line"><a name="l00370"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">  370</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">cudaFlow::empty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;  <span class="keywordflow">return</span> _graph._nodes.empty();</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;}</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;<span class="comment">// Procedure: device</span></div><div class="line"><a name="l00375"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ad8c0664e4dc3748f043eaa31b69c11cc">  375</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">cudaFlow::device</a>(<span class="keywordtype">int</span> d) {</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;  <span class="keywordflow">if</span>(_device != -1) {</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;    TF_THROW(<span class="stringliteral">&quot;cudaFlow has been assigned to device &quot;</span>, _device); </div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;  }</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;  _device = d;</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;}</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;<span class="comment">// Function: device</span></div><div class="line"><a name="l00383"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">  383</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">cudaFlow::device</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;  <span class="keywordflow">return</span> _device;</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;}</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;<span class="comment">// Function: noop</span></div><div class="line"><a name="l00388"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">  388</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">cudaFlow::noop</a>() {</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back( </div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;    [](cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node){</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;        ::cudaGraphAddEmptyNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0),</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;        <span class="stringliteral">&quot;failed to create a no-operation (empty) node&quot;</span></div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;      );</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;    },</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Noop&gt;{}</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;  );</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;}</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;<span class="comment">//template &lt;typename C&gt;</span></div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;<span class="comment">//cudaTask cudaFlow::host(C&amp;&amp; c) {</span></div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;<span class="comment">//  auto node = _graph.emplace_back(nstd::in_place_type_t&lt;cudaNode::Host&gt;{}, </span></div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;<span class="comment">//    [c=std::forward&lt;C&gt;(c)](cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) mutable {</span></div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;<span class="comment">//      cudaHostNodeParams p;</span></div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;<span class="comment">//      p.fn = [] (void* data) { (*static_cast&lt;C*&gt;(data))(); };</span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;<span class="comment">//      p.userData = &amp;c;</span></div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;<span class="comment">//      TF_CHECK_CUDA(</span></div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;<span class="comment">//        ::cudaGraphAddHostNode(&amp;node, graph, nullptr, 0, &amp;p),</span></div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;<span class="comment">//        &quot;failed to create a host node&quot;</span></div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;<span class="comment">//      );</span></div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;<span class="comment">//    }</span></div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;<span class="comment">//  );</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;<span class="comment">//  return cudaTask(node);</span></div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;<span class="comment">//}</span></div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;<span class="comment">// Function: kernel</span></div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00420"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">  420</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> <a class="code" href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">cudaFlow::kernel</a>(</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;  dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;) {</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;  </div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;  <span class="keyword">using</span> traits = function_traits&lt;F&gt;;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;  static_assert(traits::arity == <span class="keyword">sizeof</span>...(ArgsT), <span class="stringliteral">&quot;arity mismatches&quot;</span>);</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;  </div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;    [g, b, s, f=(<span class="keywordtype">void</span>*)f, args...] </div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;    (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;      cudaKernelNodeParams p;</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;      void* arguments[sizeof...(ArgsT)] = { (void*)(&amp;args)... };</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;      p.func = f;</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;      p.gridDim = g;</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;      p.blockDim = b;</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;      p.sharedMemBytes = s;</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;      p.kernelParams = arguments;</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;      p.extra = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;        ::cudaGraphAddKernelNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of kernel task&quot;</span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;      );</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;    },</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Kernel&gt;{}</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;  );</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;  </div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;  <span class="keywordflow">return</span> cudaTask(node);</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;}</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="comment">// Function: kernel</span></div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span>... ArgsT&gt;</div><div class="line"><a name="l00454"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">  454</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::kernel_on(</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;  <span class="keywordtype">int</span> d, dim3 g, dim3 b, <span class="keywordtype">size_t</span> s, F&amp;&amp; f, ArgsT&amp;&amp;... args</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;) {</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;  </div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;  <span class="keyword">using</span> traits = function_traits&lt;F&gt;;</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;  static_assert(traits::arity == <span class="keyword">sizeof</span>...(ArgsT), <span class="stringliteral">&quot;arity mismatches&quot;</span>);</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  </div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;    [d, g, b, s, f=(<span class="keywordtype">void</span>*)f, args...] </div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;    (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;      cudaKernelNodeParams p;</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;      void* arguments[sizeof...(ArgsT)] = { (void*)(&amp;args)... };</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;      p.func = f;</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;      p.gridDim = g;</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;      p.blockDim = b;</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;      p.sharedMemBytes = s;</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;      p.kernelParams = arguments;</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;      p.extra = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;      cudaScopedDevice ctx(d);</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;        ::cudaGraphAddKernelNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of kernel_on task&quot;</span></div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;      );</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;    },</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Kernel&gt;{}</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;  );</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;  </div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;  <span class="keywordflow">return</span> cudaTask(node);</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;}</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;<span class="comment">// Function: zero</span></div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;std::enable_if_t&lt;</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;  is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;  cudaTask</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;&gt; </div><div class="line"><a name="l00493"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">  493</a></span>&#160;cudaFlow::zero(T* dst, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;    [dst, count] (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;      cudaMemsetParams p;</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;      p.dst = dst;</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;      p.value = 0;</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;      p.pitch = 0;</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;      p.elementSize = <span class="keyword">sizeof</span>(T);  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;      p.width = count;</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;      p.height = 1;</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;        cudaGraphAddMemsetNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of zero task&quot;</span></div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;      );</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;    },</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Memset&gt;{}</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;  );</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;}</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;    </div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;<span class="comment">// Function: fill</span></div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;std::enable_if_t&lt;</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;  is_pod_v&lt;T&gt; &amp;&amp; (<span class="keyword">sizeof</span>(T)==1 || <span class="keyword">sizeof</span>(T)==2 || <span class="keyword">sizeof</span>(T)==4), </div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;  <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a></div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;&gt;</div><div class="line"><a name="l00519"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">  519</a></span>&#160;cudaFlow::fill(T* dst, T value, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;    [dst, value, count] (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;      cudaMemsetParams p;</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;      p.dst = dst;</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;      <span class="comment">// perform bit-wise copy</span></div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;      p.value = 0;  <span class="comment">// crucial</span></div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;      static_assert(<span class="keyword">sizeof</span>(T) &lt;= <span class="keyword">sizeof</span>(p.value), <span class="stringliteral">&quot;internal error&quot;</span>);</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;      std::memcpy(&amp;p.value, &amp;value, <span class="keyword">sizeof</span>(T));</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;      p.pitch = 0;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;      p.elementSize = <span class="keyword">sizeof</span>(T);  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;      p.width = count;</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;      p.height = 1;</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;        cudaGraphAddMemsetNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of fill task&quot;</span></div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;      );</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;    },</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Memset&gt;{}</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;  );</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;}</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;<span class="comment">// Function: copy</span></div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;<span class="keyword">template</span> &lt;</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;  <span class="keyword">typename</span> T,</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;  std::enable_if_t&lt;!std::is_same&lt;T, void&gt;::value, <span class="keywordtype">void</span>&gt;*</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;&gt;</div><div class="line"><a name="l00549"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">  549</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::copy(T* tgt, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> num) {</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;  <span class="keyword">using</span> U = std::decay_t&lt;T&gt;;</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;    [tgt, src, num] (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;      cudaMemcpy3DParms p;</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;      p.srcArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;      p.srcPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;      p.srcPtr = ::make_cudaPitchedPtr(const_cast&lt;T*&gt;(src), num*<span class="keyword">sizeof</span>(U), num, 1);</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;      p.dstArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;      p.dstPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;      p.dstPtr = ::make_cudaPitchedPtr(tgt, num*<span class="keyword">sizeof</span>(U), num, 1);</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;      p.extent = ::make_cudaExtent(num*<span class="keyword">sizeof</span>(U), 1, 1);</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;      p.kind = cudaMemcpyDefault;</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;        cudaGraphAddMemcpyNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of copy task&quot;</span></div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;      );</div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;    },</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Copy&gt;{}</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;  );</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;}</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;<span class="comment">// Function: memset</span></div><div class="line"><a name="l00578"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">  578</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::memset(<span class="keywordtype">void</span>* dst, <span class="keywordtype">int</span> ch, <span class="keywordtype">size_t</span> count) {</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;</div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;    [dst, ch, count] (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;      cudaMemsetParams p;</div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;      p.dst = dst;</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;      p.value = ch;</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;      p.pitch = 0;</div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;      <span class="comment">//p.elementSize = (count &amp; 1) == 0 ? ((count &amp; 3) == 0 ? 4 : 2) : 1;</span></div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;      <span class="comment">//p.width = (count &amp; 1) == 0 ? ((count &amp; 3) == 0 ? count &gt;&gt; 2 : count &gt;&gt; 1) : count;</span></div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;      p.elementSize = 1;  <span class="comment">// either 1, 2, or 4</span></div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;      p.width = count;</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;      p.height = 1;</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;        cudaGraphAddMemsetNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of memset task&quot;</span></div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;      );</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;    },</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Memset&gt;{}</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;  );</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;  </div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;}</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;<span class="comment">// Function: memcpy</span></div><div class="line"><a name="l00603"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">  603</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::memcpy(<span class="keywordtype">void</span>* tgt, <span class="keyword">const</span> <span class="keywordtype">void</span>* src, <span class="keywordtype">size_t</span> bytes) {</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;  <span class="keyword">auto</span> node = _graph.emplace_back(</div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;    [tgt, src, bytes] (cudaGraph_t&amp; graph, cudaGraphNode_t&amp; node) <span class="keyword">mutable</span> {</div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;      <span class="comment">// Parameters in cudaPitchedPtr</span></div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;      <span class="comment">// d   - Pointer to allocated memory</span></div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;      <span class="comment">// p   - Pitch of allocated memory in bytes</span></div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;      <span class="comment">// xsz - Logical width of allocation in elements</span></div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;      <span class="comment">// ysz - Logical height of allocation in elements</span></div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;      cudaMemcpy3DParms p;</div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;      p.srcArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;      p.srcPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;      p.srcPtr = ::make_cudaPitchedPtr(const_cast&lt;void*&gt;(src), bytes, bytes, 1);</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;      p.dstArray = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;      p.dstPos = ::make_cudaPos(0, 0, 0);</div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;      p.dstPtr = ::make_cudaPitchedPtr(tgt, bytes, bytes, 1);</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;      p.extent = ::make_cudaExtent(bytes, 1, 1);</div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;      p.kind = cudaMemcpyDefault;</div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;      TF_CHECK_CUDA(</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;        cudaGraphAddMemcpyNode(&amp;node, graph, <span class="keyword">nullptr</span>, 0, &amp;p),</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;        <span class="stringliteral">&quot;failed to create a cudaGraph node of memcpy task&quot;</span></div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;      );</div><div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;    },</div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;    nstd::in_place_type_t&lt;cudaNode::Copy&gt;{}</div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;  );</div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtf_1_1cudaTask.html">cudaTask</a>(node);</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;}</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;    </div><div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;<span class="comment">// Function: for_each</span></div><div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00632"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">  632</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::for_each(I first, I last, C&amp;&amp; c) {</div><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;  </div><div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;  <span class="keywordtype">size_t</span> N = std::distance(first, last);</div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;  <span class="keywordtype">size_t</span> B = cuda_default_threads_per_block(N);</div><div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;  <span class="keywordflow">return</span> kernel(</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;    (N+B-1) / B, B, 0, cuda_for_each&lt;I, C&gt;, first, N, std::forward&lt;C&gt;(c)</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;  );</div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;}</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;<span class="comment">// Function: for_each_index</span></div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> I, <span class="keyword">typename</span> C&gt;</div><div class="line"><a name="l00644"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">  644</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::for_each_index(I beg, I end, I inc, C&amp;&amp; c) {</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;      </div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;  <span class="keywordflow">if</span>(is_range_invalid(beg, end, inc)) {</div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;    TF_THROW(<span class="stringliteral">&quot;invalid range [&quot;</span>, beg, <span class="stringliteral">&quot;, &quot;</span>, end, <span class="stringliteral">&quot;) with inc size &quot;</span>, inc);</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;  }</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;        </div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;  <span class="keywordtype">size_t</span> N = distance(beg, end, inc);</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;  <span class="keywordflow">if</span>(N == 0) {</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;    <span class="keywordflow">return</span> noop();</div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;  }</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;      </div><div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;  <span class="keywordtype">size_t</span> B = cuda_default_threads_per_block(N);</div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;  <span class="keywordflow">return</span> kernel(</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;    (N+B-1) / B, B, 0, cuda_for_each_index&lt;I, C&gt;, beg, inc, N, std::forward&lt;C&gt;(c)</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;  );</div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;}</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;<span class="comment">// Function: transform</span></div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> C, <span class="keyword">typename</span>... S&gt;</div><div class="line"><a name="l00665"></a><span class="lineno"><a class="line" href="classtf_1_1cudaFlow.html#a56d0389eeca479ba73419bc011c1a23e">  665</a></span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::transform(T* tgt, <span class="keywordtype">size_t</span> N, C&amp;&amp; c, S*... srcs) {</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;  </div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;  <span class="keywordflow">if</span>(N == 0) {</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;    <span class="keywordflow">return</span> noop();</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;  }</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;  </div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;  <span class="keywordtype">size_t</span> B = cuda_default_threads_per_block(N);</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;  <span class="keywordflow">return</span> kernel(</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;    (N+B-1) / B, B, 0, cuda_transform&lt;T, C, S...&gt;, </div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;    tgt, N, std::forward&lt;C&gt;(c), srcs...</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;  );</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;}</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;<span class="comment">// Function: row-wise matrix transpose</span></div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;<a class="code" href="classtf_1_1cudaTask.html">cudaTask</a> cudaFlow::transpose(<span class="keyword">const</span> T* d_in, T* d_out, <span class="keywordtype">size_t</span> rows, <span class="keywordtype">size_t</span> cols) {</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;  <span class="keywordflow">if</span>(rows == 0 || cols == 0) {</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;    <span class="keywordflow">return</span> noop();</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;  }</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;</div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;  <span class="keywordtype">size_t</span> grid_dimx = (cols + 31) / 32;</div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;  <span class="keywordtype">size_t</span> grid_dimy = (rows + 31) / 32;</div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;  </div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;  <span class="keywordflow">return</span> kernel(</div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;    dim3(grid_dimx, grid_dimy, 1),</div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;    dim3(32, 8, 1),</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;    0,</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;    cuda_transpose&lt;T&gt;,</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;    d_in,</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;    d_out,</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;    rows,</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;    cols</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;  );</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;}</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;<span class="comment">//template &lt;typename T, typename B&gt;&gt;</span></div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;<span class="comment">//cudaTask cudaFlow::reduce(T* tgt, size_t N, T&amp; init, B&amp;&amp; op) {</span></div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;  <span class="comment">//if(N == 0) {</span></div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;    <span class="comment">//return noop();</span></div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;  <span class="comment">//}</span></div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;  <span class="comment">//size_t B = cuda_default_threads_per_block(N);</span></div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;<span class="comment">//}</span></div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;</div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;}  <span class="comment">// end of namespace tf -----------------------------------------------------</span></div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;</div><div class="ttc" id="classtf_1_1cudaFlow_html_a97c248490dbde983378f757239eaed4a"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a97c248490dbde983378f757239eaed4a">tf::cudaFlow::for_each</a></div><div class="ttdeci">cudaTask for_each(I first, I last, C &amp;&amp;callable)</div><div class="ttdoc">applies a callable to each dereferenced element of the data array </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:632</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ad37637606f0643f360e9eda1f9a6e559"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">tf::cudaFlow::memcpy</a></div><div class="ttdeci">cudaTask memcpy(void *tgt, const void *src, size_t bytes)</div><div class="ttdoc">creates a memcpy task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:603</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_af03e04771b655f9e629eb4c22e19b19f"><div class="ttname"><a href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">tf::cudaFlow::copy</a></div><div class="ttdeci">cudaTask copy(T *tgt, const T *src, size_t num)</div><div class="ttdoc">creates a copy task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:549</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_aee1fa4aff12a41737ea585fa2e106a35"><div class="ttname"><a href="classtf_1_1cudaFlow.html#aee1fa4aff12a41737ea585fa2e106a35">tf::cudaFlow::fill</a></div><div class="ttdeci">std::enable_if_t&lt; is_pod_v&lt; T &gt; &amp;&amp;(sizeof(T)==1||sizeof(T)==2||sizeof(T)==4), cudaTask &gt; fill(T *dst, T value, size_t count)</div><div class="ttdoc">creates a fill task that fills a typed memory block with a value </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:519</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_ab5a7c12e383be4972844a9f29033e487"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ab5a7c12e383be4972844a9f29033e487">tf::cudaFlow::for_each_index</a></div><div class="ttdeci">cudaTask for_each_index(I first, I last, I step, C &amp;&amp;callable)</div><div class="ttdoc">applies a callable to each index in the range with the step size </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:644</div></div>
<div class="ttc" id="namespacetf_html"><div class="ttname"><a href="namespacetf.html">tf</a></div><div class="ttdef"><b>Definition:</b> error.hpp:9</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a079ca65da35301e5aafd45878a19e9d2"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">tf::cudaFlow::memset</a></div><div class="ttdeci">cudaTask memset(void *dst, int v, size_t count)</div><div class="ttdoc">creates a memset task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:578</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a1926f45a038d8faa9c1b1ee43fd29a93"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a1926f45a038d8faa9c1b1ee43fd29a93">tf::cudaFlow::empty</a></div><div class="ttdeci">bool empty() const</div><div class="ttdoc">queries the emptiness of the graph </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:370</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html"><div class="ttname"><a href="classtf_1_1cudaFlow.html">tf::cudaFlow</a></div><div class="ttdoc">methods for building a CUDA task dependency graph. </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:26</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a30b2e107cb2c90a37f467b28d1b42a74"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a30b2e107cb2c90a37f467b28d1b42a74">tf::cudaFlow::noop</a></div><div class="ttdeci">cudaTask noop()</div><div class="ttdoc">creates a no-operation task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:388</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_adb731be71bdd436dfb5e36e6213a9a17"><div class="ttname"><a href="classtf_1_1cudaFlow.html#adb731be71bdd436dfb5e36e6213a9a17">tf::cudaFlow::kernel</a></div><div class="ttdeci">cudaTask kernel(dim3 g, dim3 b, size_t s, F &amp;&amp;f, ArgsT &amp;&amp;... args)</div><div class="ttdoc">creates a kernel task </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:420</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_aea77b710bf74fb3ccc6043592d4cdbc7"><div class="ttname"><a href="classtf_1_1cudaFlow.html#aea77b710bf74fb3ccc6043592d4cdbc7">tf::cudaFlow::join_until</a></div><div class="ttdeci">void join_until(P &amp;&amp;predicate)</div><div class="ttdoc">offloads the cudaFlow with the given stop predicate and then joins the execution </div><div class="ttdef"><b>Definition:</b> executor.hpp:1432</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a4a839dbaa01237a440edfebe8faf4e5b"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b">tf::cudaFlow::kernel_on</a></div><div class="ttdeci">cudaTask kernel_on(int d, dim3 g, dim3 b, size_t s, F &amp;&amp;f, ArgsT &amp;&amp;... args)</div><div class="ttdoc">creates a kernel task on a device </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:454</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_afa479a33e555179c400ba2376b7c5f29"><div class="ttname"><a href="classtf_1_1cudaFlow.html#afa479a33e555179c400ba2376b7c5f29">tf::cudaFlow::join</a></div><div class="ttdeci">void join()</div><div class="ttdoc">offloads the cudaFlow once and then joins the execution </div><div class="ttdef"><b>Definition:</b> executor.hpp:1448</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a2905a7772fb2c25753e1ae72bb05861b"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a2905a7772fb2c25753e1ae72bb05861b">tf::cudaFlow::device</a></div><div class="ttdeci">int device() const</div><div class="ttdoc">queries the device associated with the cudaFlow </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:383</div></div>
<div class="ttc" id="classtf_1_1cudaTask_html"><div class="ttname"><a href="classtf_1_1cudaTask.html">tf::cudaTask</a></div><div class="ttdoc">handle to a node in a cudaGraph </div><div class="ttdef"><b>Definition:</b> cuda_task.hpp:12</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a56d0389eeca479ba73419bc011c1a23e"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a56d0389eeca479ba73419bc011c1a23e">tf::cudaFlow::transform</a></div><div class="ttdeci">cudaTask transform(T *tgt, size_t N, C &amp;&amp;callable, S *... srcs)</div><div class="ttdoc">applies a callable to a source range and stores the result in a target ange </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:665</div></div>
<div class="ttc" id="classtf_1_1Executor_html"><div class="ttname"><a href="classtf_1_1Executor.html">tf::Executor</a></div><div class="ttdoc">execution interface for running a taskflow graph </div><div class="ttdef"><b>Definition:</b> executor.hpp:24</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a91c1739bb9a2832f306f3d12693a0994"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a91c1739bb9a2832f306f3d12693a0994">tf::cudaFlow::zero</a></div><div class="ttdeci">std::enable_if_t&lt; is_pod_v&lt; T &gt; &amp;&amp;(sizeof(T)==1||sizeof(T)==2||sizeof(T)==4), cudaTask &gt; zero(T *dst, size_t count)</div><div class="ttdoc">creates a zero task that zeroes a typed memory block </div><div class="ttdef"><b>Definition:</b> cuda_flow.hpp:493</div></div>
<div class="ttc" id="classtf_1_1cudaFlow_html_a9b28ad99e4d3c0208422a2db094df277"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a9b28ad99e4d3c0208422a2db094df277">tf::cudaFlow::join_n</a></div><div class="ttdeci">void join_n(size_t N)</div><div class="ttdoc">offloads the cudaFlow by the given times and then joins the execution </div><div class="ttdef"><b>Definition:</b> executor.hpp:1443</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_88dad41ea55ca2177e141d32a93e931c.html">taskflow</a></li><li class="navelem"><a class="el" href="dir_638d51f8e6f20ea8c720cc8c006296ba.html">cuda</a></li><li class="navelem"><b>cuda_flow.hpp</b></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
